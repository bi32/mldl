# å› æœæ¨ç†ç†è®ºï¼šä»ç›¸å…³åˆ°å› æœçš„è·¨è¶Š ğŸ”—

æ·±å…¥ç†è§£å› æœæ¨ç†çš„æ ¸å¿ƒç†è®ºï¼Œä»å›¾æ¨¡å‹åˆ°å®éªŒè®¾è®¡ã€‚

## 1. å› æœæ¨ç†åŸºç¡€ ğŸ¯

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
import networkx as nx
from typing import List, Tuple, Dict
import warnings
warnings.filterwarnings('ignore')

class CausalInferenceBasics:
    """å› æœæ¨ç†åŸºç¡€æ¦‚å¿µ"""
    
    def __init__(self):
        self.concepts = {}
    
    def correlation_vs_causation(self):
        """ç›¸å…³æ€§vså› æœæ€§"""
        print("=== ç›¸å…³æ€§ vs å› æœæ€§ ===")
        
        print("ç›¸å…³æ€§ (Correlation):")
        print("- å®šä¹‰: ä¸¤ä¸ªå˜é‡é—´çš„ç»Ÿè®¡å…³è”")
        print("- åº¦é‡: ç›¸å…³ç³»æ•°ã€äº’ä¿¡æ¯ç­‰")
        print("- æ€§è´¨: å¯¹ç§°ã€æ˜“äºæµ‹é‡")
        print("- å±€é™: ä¸èƒ½ç¡®å®šå› æœæ–¹å‘")
        print()
        
        print("å› æœæ€§ (Causation):")
        print("- å®šä¹‰: ä¸€ä¸ªå˜é‡å¯¹å¦ä¸€ä¸ªå˜é‡çš„å› æœå½±å“")
        print("- ç‰¹å¾: éå¯¹ç§°ã€æœ‰æ–¹å‘æ€§")
        print("- æ¡ä»¶: æ—¶é—´å…ˆåã€æœºåˆ¶å¯ä¿¡")
        print("- é‡è¦æ€§: é¢„æµ‹å¹²é¢„æ•ˆæœ")
        print()
        
        print("ç»å…¸è¯¯åŒº:")
        fallacies = {
            "è™šå‡ç›¸å…³": {
                "æè¿°": "ç¬¬ä¸‰å˜é‡å¯¼è‡´çš„ç›¸å…³æ€§",
                "ä¾‹å­": "å†°æ·‡æ·‹é”€é‡ä¸æººæ°´æ­»äº¡ç‡",
                "çœŸç›¸": "æ¸©åº¦æ˜¯å…±åŒåŸå› ",
                "æ•™è®­": "éœ€è¦æ§åˆ¶æ··æ‚å˜é‡"
            },
            "åå‘å› æœ": {
                "æè¿°": "å› æœæ–¹å‘åˆ¤æ–­é”™è¯¯",
                "ä¾‹å­": "è´¢å¯Œä¸å¥åº·çš„å…³ç³»",
                "é—®é¢˜": "æ˜¯è´¢å¯Œå¯¼è‡´å¥åº·è¿˜æ˜¯ç›¸åï¼Ÿ",
                "è§£å†³": "å·¥å…·å˜é‡ã€è‡ªç„¶å®éªŒ"
            },
            "é€‰æ‹©åå·®": {
                "æè¿°": "æ ·æœ¬é€‰æ‹©å¯¼è‡´çš„åå·®",
                "ä¾‹å­": "å¤§å­¦æ•™è‚²ä¸æ”¶å…¥",
                "åå·®": "èƒ½åŠ›ç­‰ä¸å¯è§‚æµ‹å› ç´ ",
                "æ–¹æ³•": "éšæœºåŒ–ã€å›å½’ä¸è¿ç»­"
            }
        }
        
        for fallacy, details in fallacies.items():
            print(f"{fallacy}:")
            for key, value in details.items():
                print(f"  {key}: {value}")
            print()
        
        # å¯è§†åŒ–ç›¸å…³æ€§ä¸å› æœæ€§
        self.visualize_correlation_causation()
        
        return fallacies
    
    def visualize_correlation_causation(self):
        """å¯è§†åŒ–ç›¸å…³æ€§ä¸å› æœæ€§çš„åŒºåˆ«"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        np.random.seed(42)
        n = 1000
        
        # 1. çœŸå®å› æœå…³ç³»: X -> Y
        X1 = np.random.normal(0, 1, n)
        Y1 = 2 * X1 + np.random.normal(0, 0.5, n)
        
        axes[0, 0].scatter(X1, Y1, alpha=0.6, s=10)
        axes[0, 0].set_xlabel('X')
        axes[0, 0].set_ylabel('Y')
        axes[0, 0].set_title(f'çœŸå®å› æœ: Xâ†’Y\nç›¸å…³ç³»æ•°={np.corrcoef(X1, Y1)[0,1]:.3f}')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ å›å½’çº¿
        z = np.polyfit(X1, Y1, 1)
        p = np.poly1d(z)
        axes[0, 0].plot(X1, p(X1), "r--", alpha=0.8)
        
        # 2. è™šå‡ç›¸å…³: Z -> X, Z -> Y
        Z = np.random.normal(0, 1, n)
        X2 = Z + np.random.normal(0, 0.3, n)
        Y2 = -Z + np.random.normal(0, 0.3, n)
        
        axes[0, 1].scatter(X2, Y2, alpha=0.6, s=10, color='orange')
        axes[0, 1].set_xlabel('X')
        axes[0, 1].set_ylabel('Y')
        axes[0, 1].set_title(f'è™šå‡ç›¸å…³: Zâ†’X, Zâ†’Y\nç›¸å…³ç³»æ•°={np.corrcoef(X2, Y2)[0,1]:.3f}')
        axes[0, 1].grid(True, alpha=0.3)
        
        z = np.polyfit(X2, Y2, 1)
        p = np.poly1d(z)
        axes[0, 1].plot(X2, p(X2), "r--", alpha=0.8)
        
        # 3. ç¢°æ’å™¨åå·®: X -> Z <- Y
        X3 = np.random.normal(0, 1, n)
        Y3 = np.random.normal(0, 1, n)  # Xå’ŒYç‹¬ç«‹
        Z3 = X3 + Y3 + np.random.normal(0, 0.1, n)
        
        # æ¡ä»¶äºZçš„å­æ ·æœ¬
        mask = Z3 > np.percentile(Z3, 80)  # é€‰æ‹©Zå€¼è¾ƒå¤§çš„æ ·æœ¬
        X3_cond = X3[mask]
        Y3_cond = Y3[mask]
        
        axes[0, 2].scatter(X3_cond, Y3_cond, alpha=0.6, s=10, color='green')
        axes[0, 2].set_xlabel('X')
        axes[0, 2].set_ylabel('Y')
        axes[0, 2].set_title(f'ç¢°æ’å™¨åå·®: æ¡ä»¶äºZ\nç›¸å…³ç³»æ•°={np.corrcoef(X3_cond, Y3_cond)[0,1]:.3f}')
        axes[0, 2].grid(True, alpha=0.3)
        
        z = np.polyfit(X3_cond, Y3_cond, 1)
        p = np.poly1d(z)
        axes[0, 2].plot(X3_cond, p(X3_cond), "r--", alpha=0.8)
        
        # 4-6. å¯¹åº”çš„å› æœå›¾
        causal_structures = [
            ("X â†’ Y", [(0, 1)], ['X', 'Y']),
            ("Z â†’ X, Z â†’ Y", [(0, 1), (0, 2)], ['Z', 'X', 'Y']),
            ("X â†’ Z â† Y", [(0, 2), (1, 2)], ['X', 'Y', 'Z'])
        ]
        
        for i, (title, edges, labels) in enumerate(causal_structures):
            ax = axes[1, i]
            G = nx.DiGraph()
            G.add_edges_from(edges)
            
            pos = nx.spring_layout(G, seed=42)
            nx.draw(G, pos, ax=ax, with_labels=True, labels={i: labels[i] for i in range(len(labels))},
                   node_color='lightblue', node_size=1000, font_size=12, arrows=True, arrowsize=20)
            ax.set_title(f'å› æœç»“æ„: {title}')
        
        plt.tight_layout()
        plt.show()
    
    def causal_hierarchy(self):
        """å› æœå±‚æ¬¡ç»“æ„"""
        print("=== å› æœå±‚æ¬¡ç»“æ„ (Ladder of Causation) ===")
        
        print("Judea Pearlçš„å› æœå±‚æ¬¡:")
        hierarchy = {
            "ç¬¬ä¸€å±‚: å…³è” (Association)": {
                "é—®é¢˜": "è§‚å¯Ÿåˆ°çš„ç›¸å…³æ€§æ˜¯ä»€ä¹ˆï¼Ÿ",
                "ç¬¦å·": "P(y|x) - æ¡ä»¶æ¦‚ç‡",
                "ä¾‹å­": "æœè¯çš„ç—…äººåº·å¤ç‡å¦‚ä½•ï¼Ÿ",
                "æ•°æ®": "è§‚å¯Ÿæ•°æ®",
                "æ–¹æ³•": "ç»Ÿè®¡å…³è”ã€æœºå™¨å­¦ä¹ "
            },
            "ç¬¬äºŒå±‚: å¹²é¢„ (Intervention)": {
                "é—®é¢˜": "å¦‚æœæˆ‘ä»¬å¹²é¢„ä¼šæ€æ ·ï¼Ÿ",
                "ç¬¦å·": "P(y|do(x)) - å¹²é¢„åˆ†å¸ƒ",
                "ä¾‹å­": "å¦‚æœç»™ç—…äººæœè¯ä¼šå¦‚ä½•ï¼Ÿ",
                "æ•°æ®": "å®éªŒæ•°æ®æˆ–å› æœæ¨¡å‹",
                "æ–¹æ³•": "éšæœºå®éªŒã€å› æœå›¾æ¨æ–­"
            },
            "ç¬¬ä¸‰å±‚: åäº‹å® (Counterfactuals)": {
                "é—®é¢˜": "å¦‚æœå½“æ—¶åšäº†ä¸åŒé€‰æ‹©ä¼šæ€æ ·ï¼Ÿ",
                "ç¬¦å·": "P(y_x|x',y') - åäº‹å®æ¦‚ç‡",
                "ä¾‹å­": "å¦‚æœè¿™ä¸ªåº·å¤çš„ç—…äººæ²¡æœè¯ä¼šå¦‚ä½•ï¼Ÿ",
                "æ•°æ®": "éœ€è¦å› æœæ¨¡å‹å’Œä¸ªä½“ä¿¡æ¯",
                "æ–¹æ³•": "ç»“æ„å› æœæ¨¡å‹ã€åäº‹å®æ¨ç†"
            }
        }
        
        for level, details in hierarchy.items():
            print(f"{level}:")
            for key, value in details.items():
                print(f"  {key}: {value}")
            print()
        
        # å¯è§†åŒ–å±‚æ¬¡ç»“æ„
        self.visualize_causal_hierarchy()
        
        return hierarchy
    
    def visualize_causal_hierarchy(self):
        """å¯è§†åŒ–å› æœå±‚æ¬¡ç»“æ„"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        
        # åˆ›å»ºå±‚æ¬¡å›¾
        levels = ['å…³è”\n(Association)', 'å¹²é¢„\n(Intervention)', 'åäº‹å®\n(Counterfactuals)']
        questions = ['çœ‹åˆ°äº†ä»€ä¹ˆï¼Ÿ', 'å¦‚æœåšäº†ä¼šæ€æ ·ï¼Ÿ', 'å¦‚æœå½“æ—¶ä¸åŒä¼šæ€æ ·ï¼Ÿ']
        examples = ['P(y|x)', 'P(y|do(x))', 'P(y_x|x\',y\')']
        
        # ç»˜åˆ¶å±‚æ¬¡ç»“æ„
        y_positions = [0.2, 0.5, 0.8]
        colors = ['lightblue', 'lightgreen', 'lightcoral']
        
        for i, (level, question, example, y_pos, color) in enumerate(zip(levels, questions, examples, y_positions, colors)):
            # ç»˜åˆ¶å±‚æ¬¡æ¡†
            rect = plt.Rectangle((0.1, y_pos-0.08), 0.8, 0.16, 
                               facecolor=color, edgecolor='black', linewidth=2)
            ax.add_patch(rect)
            
            # æ·»åŠ æ–‡æœ¬
            ax.text(0.15, y_pos+0.03, level, fontsize=14, weight='bold')
            ax.text(0.15, y_pos-0.02, question, fontsize=12)
            ax.text(0.15, y_pos-0.06, example, fontsize=11, style='italic')
            
            # æ·»åŠ å±‚æ¬¡æ ‡ç­¾
            ax.text(0.05, y_pos, f'ç¬¬{i+1}å±‚', fontsize=12, weight='bold', 
                   ha='right', va='center')
        
        # æ·»åŠ ç®­å¤´è¡¨ç¤ºå±‚æ¬¡é€’è¿›
        for i in range(len(y_positions)-1):
            ax.annotate('', xy=(0.5, y_positions[i+1]-0.08), xytext=(0.5, y_positions[i]+0.08),
                       arrowprops=dict(arrowstyle='->', lw=2, color='red'))
        
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.set_title('å› æœæ¨ç†çš„å±‚æ¬¡ç»“æ„', fontsize=16, weight='bold')
        ax.axis('off')
        
        # æ·»åŠ è¯´æ˜
        ax.text(0.95, 0.1, 'å¤æ‚åº¦å’Œæ´å¯ŸåŠ›é€’å¢', fontsize=12, 
               ha='right', style='italic', color='red')
        
        plt.tight_layout()
        plt.show()

class CausalGraphicalModels:
    """å› æœå›¾æ¨¡å‹"""
    
    def __init__(self):
        pass
    
    def directed_acyclic_graphs(self):
        """æœ‰å‘æ— ç¯å›¾(DAG)"""
        print("=== æœ‰å‘æ— ç¯å›¾ (DAG) ===")
        
        print("åŸºæœ¬æ¦‚å¿µ:")
        print("- èŠ‚ç‚¹: å˜é‡")
        print("- æœ‰å‘è¾¹: ç›´æ¥å› æœå…³ç³»")
        print("- æ— ç¯: ä¸å­˜åœ¨å› æœå¾ªç¯")
        print("- è·¯å¾„: èŠ‚ç‚¹é—´çš„è¿æ¥åºåˆ—")
        print()
        
        concepts = {
            "çˆ¶èŠ‚ç‚¹": "ç›´æ¥æŒ‡å‘æŸèŠ‚ç‚¹çš„èŠ‚ç‚¹",
            "å­èŠ‚ç‚¹": "è¢«æŸèŠ‚ç‚¹ç›´æ¥æŒ‡å‘çš„èŠ‚ç‚¹", 
            "ç¥–å…ˆ": "é€šè¿‡æœ‰å‘è·¯å¾„èƒ½åˆ°è¾¾æŸèŠ‚ç‚¹çš„èŠ‚ç‚¹",
            "åä»£": "ä»æŸèŠ‚ç‚¹é€šè¿‡æœ‰å‘è·¯å¾„èƒ½åˆ°è¾¾çš„èŠ‚ç‚¹",
            "æ ¹èŠ‚ç‚¹": "æ²¡æœ‰çˆ¶èŠ‚ç‚¹çš„èŠ‚ç‚¹",
            "å¶èŠ‚ç‚¹": "æ²¡æœ‰å­èŠ‚ç‚¹çš„èŠ‚ç‚¹"
        }
        
        for concept, definition in concepts.items():
            print(f"{concept}: {definition}")
        print()
        
        print("è·¯å¾„ç±»å‹:")
        path_types = {
            "æœ‰å‘è·¯å¾„": {
                "å®šä¹‰": "æ‰€æœ‰è¾¹éƒ½æŒ‡å‘åŒä¸€æ–¹å‘",
                "æ„ä¹‰": "å› æœé“¾",
                "ä¾‹å­": "X â†’ Y â†’ Z"
            },
            "åé—¨è·¯å¾„": {
                "å®šä¹‰": "ä»Xåˆ°Yä¸”ä»¥æŒ‡å‘Xçš„è¾¹å¼€å§‹",
                "æ„ä¹‰": "æ··æ‚è·¯å¾„",
                "ä¾‹å­": "X â† Z â†’ Y"
            },
            "å‰é—¨è·¯å¾„": {
                "å®šä¹‰": "ä»Xåˆ°Yä¸”ä»¥ä»Xå‡ºå‘çš„è¾¹å¼€å§‹",
                "æ„ä¹‰": "ä¸­ä»‹è·¯å¾„",
                "ä¾‹å­": "X â†’ M â†’ Y"
            }
        }
        
        for path_type, details in path_types.items():
            print(f"{path_type}:")
            for key, value in details.items():
                print(f"  {key}: {value}")
            print()
        
        # å¯è§†åŒ–DAGæ¦‚å¿µ
        self.visualize_dag_concepts()
        
        return path_types
    
    def visualize_dag_concepts(self):
        """å¯è§†åŒ–DAGæ¦‚å¿µ"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. åŸºæœ¬DAGç»“æ„
        G1 = nx.DiGraph()
        G1.add_edges_from([('X', 'Y'), ('Z', 'X'), ('Z', 'Y'), ('W', 'Z')])
        
        pos1 = {'W': (0, 1), 'Z': (1, 1), 'X': (0, 0), 'Y': (2, 0)}
        nx.draw(G1, pos1, ax=axes[0, 0], with_labels=True, 
                node_color='lightblue', node_size=1000, font_size=12, 
                arrows=True, arrowsize=20)
        axes[0, 0].set_title('åŸºæœ¬DAGç»“æ„')
        
        # 2. ä¸‰ç§åŸºæœ¬ç»“æ„
        structures = [
            ("é“¾å¼: Xâ†’Yâ†’Z", [('X', 'Y'), ('Y', 'Z')]),
            ("åˆ†å‰: Xâ†Yâ†’Z", [('Y', 'X'), ('Y', 'Z')]),
            ("ç¢°æ’: Xâ†’Yâ†Z", [('X', 'Y'), ('Z', 'Y')])
        ]
        
        for i, (title, edges) in enumerate(structures):
            G = nx.DiGraph()
            G.add_edges_from(edges)
            
            if i == 0:  # é“¾å¼
                pos = {'X': (0, 0), 'Y': (1, 0), 'Z': (2, 0)}
            elif i == 1:  # åˆ†å‰
                pos = {'Y': (1, 1), 'X': (0, 0), 'Z': (2, 0)}
            else:  # ç¢°æ’
                pos = {'X': (0, 1), 'Z': (2, 1), 'Y': (1, 0)}
            
            if i == 0:
                ax = axes[0, 1]
            else:
                ax = axes[1, i-1]
                
            nx.draw(G, pos, ax=ax, with_labels=True,
                   node_color='lightgreen', node_size=800, font_size=12,
                   arrows=True, arrowsize=20)
            ax.set_title(title)
        
        # åˆ é™¤ç©ºçš„å­å›¾
        axes[1, 2].remove()
        
        plt.tight_layout()
        plt.show()
    
    def d_separation(self):
        """d-åˆ†ç¦»"""
        print("=== d-åˆ†ç¦» (d-separation) ===")
        
        print("å®šä¹‰:")
        print("ç»™å®šè§‚å¯Ÿé›†åˆZï¼Œè·¯å¾„Påœ¨ä»¥ä¸‹æƒ…å†µè¢«é˜»æ–­:")
        print("1. é“¾å¼æˆ–åˆ†å‰ç»“æ„ä¸­ï¼Œä¸­é—´èŠ‚ç‚¹åœ¨Zä¸­")
        print("2. ç¢°æ’ç»“æ„ä¸­ï¼Œç¢°æ’èŠ‚ç‚¹åŠå…¶åä»£éƒ½ä¸åœ¨Zä¸­")
        print()
        
        print("d-åˆ†ç¦»è§„åˆ™:")
        rules = {
            "é“¾å¼ Xâ†’Yâ†’Z": {
                "ç»“æ„": "Xé€šè¿‡Yå½±å“Z",
                "æ¡ä»¶äºY": "é˜»æ–­è·¯å¾„ï¼ŒXâŠ¥Z|Y",
                "ä¸æ¡ä»¶": "è·¯å¾„å¼€æ”¾ï¼ŒXå’ŒZç›¸å…³",
                "å«ä¹‰": "æ§åˆ¶ä¸­ä»‹å˜é‡é˜»æ–­å› æœé“¾"
            },
            "åˆ†å‰ Xâ†Yâ†’Z": {
                "ç»“æ„": "Yæ˜¯Xå’ŒZçš„å…±åŒåŸå› ",
                "æ¡ä»¶äºY": "é˜»æ–­è·¯å¾„ï¼ŒXâŠ¥Z|Y", 
                "ä¸æ¡ä»¶": "è·¯å¾„å¼€æ”¾ï¼ŒXå’ŒZç›¸å…³",
                "å«ä¹‰": "æ§åˆ¶æ··æ‚å˜é‡æ¶ˆé™¤è™šå‡ç›¸å…³"
            },
            "ç¢°æ’ Xâ†’Yâ†Z": {
                "ç»“æ„": "Yæ˜¯Xå’ŒZçš„å…±åŒç»“æœ",
                "æ¡ä»¶äºY": "å¼€æ”¾è·¯å¾„ï¼ŒXå’ŒZç›¸å…³",
                "ä¸æ¡ä»¶": "è·¯å¾„é˜»æ–­ï¼ŒXâŠ¥Z",
                "å«ä¹‰": "æ§åˆ¶ç¢°æ’å˜é‡äº§ç”Ÿè™šå‡ç›¸å…³"
            }
        }
        
        for structure, details in rules.items():
            print(f"{structure}:")
            for key, value in details.items():
                print(f"  {key}: {value}")
            print()
        
        # æ¼”ç¤ºd-åˆ†ç¦»
        self.demonstrate_d_separation()
        
        return rules
    
    def demonstrate_d_separation(self):
        """æ¼”ç¤ºd-åˆ†ç¦»æ¦‚å¿µ"""
        np.random.seed(42)
        n = 1000
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        # 1. é“¾å¼ç»“æ„: X â†’ Y â†’ Z
        X1 = np.random.normal(0, 1, n)
        Y1 = X1 + np.random.normal(0, 0.3, n)
        Z1 = Y1 + np.random.normal(0, 0.3, n)
        
        # ä¸æ§åˆ¶Yæ—¶çš„X-Zå…³ç³»
        axes[0, 0].scatter(X1, Z1, alpha=0.6, s=10)
        corr_xz = np.corrcoef(X1, Z1)[0, 1]
        axes[0, 0].set_title(f'é“¾å¼: Xâ†’Yâ†’Z\nä¸æ§åˆ¶Y: r(X,Z)={corr_xz:.3f}')
        axes[0, 0].set_xlabel('X')
        axes[0, 0].set_ylabel('Z')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ§åˆ¶Yåçš„æ®‹å·®å…³ç³»
        from sklearn.linear_model import LinearRegression
        reg_xy = LinearRegression().fit(X1.reshape(-1, 1), Y1)
        reg_zy = LinearRegression().fit(Y1.reshape(-1, 1), Z1)
        
        X_resid = X1 - reg_xy.predict(X1.reshape(-1, 1))
        Z_resid = Z1 - reg_zy.predict(Y1.reshape(-1, 1))
        
        axes[1, 0].scatter(X_resid, Z_resid, alpha=0.6, s=10, color='orange')
        corr_resid = np.corrcoef(X_resid, Z_resid)[0, 1]
        axes[1, 0].set_title(f'æ§åˆ¶Yåæ®‹å·®\nr(X,Z|Y)={corr_resid:.3f}')
        axes[1, 0].set_xlabel('Xæ®‹å·®')
        axes[1, 0].set_ylabel('Zæ®‹å·®')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 2. åˆ†å‰ç»“æ„: X â† Y â†’ Z
        Y2 = np.random.normal(0, 1, n)
        X2 = Y2 + np.random.normal(0, 0.3, n)
        Z2 = Y2 + np.random.normal(0, 0.3, n)
        
        axes[0, 1].scatter(X2, Z2, alpha=0.6, s=10, color='green')
        corr_xz2 = np.corrcoef(X2, Z2)[0, 1]
        axes[0, 1].set_title(f'åˆ†å‰: Xâ†Yâ†’Z\nä¸æ§åˆ¶Y: r(X,Z)={corr_xz2:.3f}')
        axes[0, 1].set_xlabel('X')
        axes[0, 1].set_ylabel('Z')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ§åˆ¶Yå
        reg_xy2 = LinearRegression().fit(Y2.reshape(-1, 1), X2)
        reg_zy2 = LinearRegression().fit(Y2.reshape(-1, 1), Z2)
        
        X_resid2 = X2 - reg_xy2.predict(Y2.reshape(-1, 1))
        Z_resid2 = Z2 - reg_zy2.predict(Y2.reshape(-1, 1))
        
        axes[1, 1].scatter(X_resid2, Z_resid2, alpha=0.6, s=10, color='green')
        corr_resid2 = np.corrcoef(X_resid2, Z_resid2)[0, 1]
        axes[1, 1].set_title(f'æ§åˆ¶Yåæ®‹å·®\nr(X,Z|Y)={corr_resid2:.3f}')
        axes[1, 1].set_xlabel('Xæ®‹å·®')
        axes[1, 1].set_ylabel('Zæ®‹å·®')
        axes[1, 1].grid(True, alpha=0.3)
        
        # 3. ç¢°æ’ç»“æ„: X â†’ Y â† Z
        X3 = np.random.normal(0, 1, n)
        Z3 = np.random.normal(0, 1, n)
        Y3 = X3 + Z3 + np.random.normal(0, 0.3, n)
        
        axes[0, 2].scatter(X3, Z3, alpha=0.6, s=10, color='red')
        corr_xz3 = np.corrcoef(X3, Z3)[0, 1]
        axes[0, 2].set_title(f'ç¢°æ’: Xâ†’Yâ†Z\nä¸æ§åˆ¶Y: r(X,Z)={corr_xz3:.3f}')
        axes[0, 2].set_xlabel('X')
        axes[0, 2].set_ylabel('Z')
        axes[0, 2].grid(True, alpha=0.3)
        
        # æ§åˆ¶Yåï¼ˆé€‰æ‹©Yå€¼è¾ƒå¤§çš„æ ·æœ¬ï¼‰
        mask = Y3 > np.percentile(Y3, 70)
        X3_cond = X3[mask]
        Z3_cond = Z3[mask]
        
        axes[1, 2].scatter(X3_cond, Z3_cond, alpha=0.6, s=10, color='red')
        corr_cond = np.corrcoef(X3_cond, Z3_cond)[0, 1]
        axes[1, 2].set_title(f'æ¡ä»¶äºY(>70%åˆ†ä½)\nr(X,Z|Y)={corr_cond:.3f}')
        axes[1, 2].set_xlabel('X')
        axes[1, 2].set_ylabel('Z')
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

class CausalIdentification:
    """å› æœè¯†åˆ«"""
    
    def __init__(self):
        pass
    
    def backdoor_criterion(self):
        """åé—¨å‡†åˆ™"""
        print("=== åé—¨å‡†åˆ™ (Backdoor Criterion) ===")
        
        print("ç›®æ ‡: è¯†åˆ«å› æœæ•ˆåº” P(Y|do(X))")
        print()
        
        print("åé—¨å‡†åˆ™æ¡ä»¶:")
        print("å˜é‡é›†åˆZæ»¡è¶³åé—¨å‡†åˆ™ï¼Œå½“ä¸”ä»…å½“:")
        print("1. Zä¸åŒ…å«Xçš„åä»£")
        print("2. Zé˜»æ–­Xåˆ°Yçš„æ‰€æœ‰åé—¨è·¯å¾„")
        print()
        
        print("åº”ç”¨:")
        print("å¦‚æœZæ»¡è¶³åé—¨å‡†åˆ™ï¼Œåˆ™:")
        print("P(Y|do(X)) = Î£_z P(Y|X,Z=z)P(Z=z)")
        print("å³ï¼šå¹²é¢„åˆ†å¸ƒ = è°ƒæ•´å…¬å¼")
        print()
        
        # å®ç°åé—¨è°ƒæ•´
        self.implement_backdoor_adjustment()
        
        return self.frontdoor_criterion()
    
    def implement_backdoor_adjustment(self):
        """å®ç°åé—¨è°ƒæ•´"""
        print("=== åé—¨è°ƒæ•´ç¤ºä¾‹ ===")
        
        # ç”Ÿæˆæ•°æ®ï¼šZ â†’ X, Z â†’ Y, X â†’ Y
        np.random.seed(42)
        n = 5000
        
        # æ··æ‚å˜é‡Z
        Z = np.random.normal(0, 1, n)
        
        # æ²»ç–—å˜é‡Xï¼ˆå—Zå½±å“ï¼‰
        X_prob = 1 / (1 + np.exp(-(Z + np.random.normal(0, 0.5, n))))
        X = np.random.binomial(1, X_prob, n)
        
        # ç»“æœå˜é‡Yï¼ˆå—Xå’ŒZå½±å“ï¼‰
        Y = 2 * X + 1.5 * Z + np.random.normal(0, 0.5, n)
        
        print("æ•°æ®ç”Ÿæˆè¿‡ç¨‹:")
        print("Z ~ N(0,1)")
        print("X ~ Bernoulli(sigmoid(Z + noise))")
        print("Y = 2*X + 1.5*Z + noise")
        print("çœŸå®å› æœæ•ˆåº”: E[Y|do(X=1)] - E[Y|do(X=0)] = 2")
        print()
        
        # 1. æœ´ç´ ä¼°è®¡ï¼ˆæœ‰åå·®ï¼‰
        naive_effect = np.mean(Y[X==1]) - np.mean(Y[X==0])
        print(f"æœ´ç´ ä¼°è®¡: {naive_effect:.3f}")
        
        # 2. åé—¨è°ƒæ•´ä¼°è®¡
        # æŒ‰Zåˆ†å±‚è®¡ç®—æ¡ä»¶æœŸæœ›
        z_bins = np.linspace(Z.min(), Z.max(), 10)
        backdoor_effect = 0
        
        for i in range(len(z_bins)-1):
            z_mask = (Z >= z_bins[i]) & (Z < z_bins[i+1])
            if np.sum(z_mask) > 0:
                y1_mean = np.mean(Y[(X==1) & z_mask]) if np.sum((X==1) & z_mask) > 0 else 0
                y0_mean = np.mean(Y[(X==0) & z_mask]) if np.sum((X==0) & z_mask) > 0 else 0
                bin_effect = (y1_mean - y0_mean) * np.mean(z_mask)
                backdoor_effect += bin_effect
        
        print(f"åé—¨è°ƒæ•´ä¼°è®¡: {backdoor_effect:.3f}")
        
        # 3. å›å½’è°ƒæ•´
        from sklearn.linear_model import LinearRegression
        
        # æ‹ŸåˆY ~ X + Z
        reg = LinearRegression()
        features = np.column_stack([X, Z])
        reg.fit(features, Y)
        
        regression_effect = reg.coef_[0]
        print(f"å›å½’è°ƒæ•´ä¼°è®¡: {regression_effect:.3f}")
        
        # å¯è§†åŒ–æ··æ‚æ•ˆåº”
        self.visualize_confounding_adjustment(X, Y, Z)
        
        return naive_effect, backdoor_effect, regression_effect
    
    def visualize_confounding_adjustment(self, X, Y, Z):
        """å¯è§†åŒ–æ··æ‚è°ƒæ•´"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # 1. åŸå§‹æ•°æ®ä¸­çš„X-Yå…³ç³»
        treated = X == 1
        control = X == 0
        
        axes[0].scatter(X[control], Y[control], alpha=0.6, label='X=0', color='blue', s=10)
        axes[0].scatter(X[treated], Y[treated], alpha=0.6, label='X=1', color='red', s=10)
        axes[0].set_xlabel('X')
        axes[0].set_ylabel('Y')
        axes[0].set_title('åŸå§‹X-Yå…³ç³»')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. Zçš„åˆ†å¸ƒå·®å¼‚
        axes[1].hist(Z[control], alpha=0.7, label='X=0', bins=30, density=True, color='blue')
        axes[1].hist(Z[treated], alpha=0.7, label='X=1', bins=30, density=True, color='red')
        axes[1].set_xlabel('Z (æ··æ‚å˜é‡)')
        axes[1].set_ylabel('å¯†åº¦')
        axes[1].set_title('ä¸åŒXç»„çš„Zåˆ†å¸ƒ')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        # 3. æŒ‰Zåˆ†å±‚çš„æ•ˆåº”
        z_bins = np.linspace(Z.min(), Z.max(), 5)
        bin_centers = []
        bin_effects = []
        
        for i in range(len(z_bins)-1):
            z_mask = (Z >= z_bins[i]) & (Z < z_bins[i+1])
            if np.sum(z_mask & (X==1)) > 10 and np.sum(z_mask & (X==0)) > 10:
                y1_mean = np.mean(Y[z_mask & (X==1)])
                y0_mean = np.mean(Y[z_mask & (X==0)])
                bin_centers.append((z_bins[i] + z_bins[i+1]) / 2)
                bin_effects.append(y1_mean - y0_mean)
        
        axes[2].bar(bin_centers, bin_effects, width=0.5, alpha=0.7, color='green')
        axes[2].axhline(y=2, color='red', linestyle='--', linewidth=2, label='çœŸå®æ•ˆåº”=2')
        axes[2].set_xlabel('ZåŒºé—´')
        axes[2].set_ylabel('Xçš„å› æœæ•ˆåº”')
        axes[2].set_title('ä¸åŒZå±‚çš„å› æœæ•ˆåº”')
        axes[2].legend()
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def frontdoor_criterion(self):
        """å‰é—¨å‡†åˆ™"""
        print("\n=== å‰é—¨å‡†åˆ™ (Frontdoor Criterion) ===")
        
        print("åº”ç”¨åœºæ™¯:")
        print("- å­˜åœ¨ä¸å¯è§‚æµ‹çš„æ··æ‚å˜é‡")
        print("- ä½†æœ‰å¯è§‚æµ‹çš„ä¸­ä»‹å˜é‡")
        print("- ä¸­ä»‹å˜é‡æ»¡è¶³ç‰¹å®šæ¡ä»¶")
        print()
        
        print("å‰é—¨å‡†åˆ™æ¡ä»¶:")
        print("å˜é‡é›†åˆMæ»¡è¶³å‰é—¨å‡†åˆ™ï¼Œå½“ä¸”ä»…å½“:")
        print("1. Mæ‹¦æˆªæ‰€æœ‰Xåˆ°Yçš„æœ‰å‘è·¯å¾„")
        print("2. Xåˆ°Mæ²¡æœ‰åé—¨è·¯å¾„")
        print("3. Mæ»¡è¶³ç›¸å¯¹äºYçš„åé—¨å‡†åˆ™ï¼ˆæ¡ä»¶äºXï¼‰")
        print()
        
        print("å‰é—¨å…¬å¼:")
        print("P(Y|do(X)) = Î£_m P(M=m|X) Î£_x' P(Y|X=x',M=m)P(X=x')")
        print()
        
        criterion_info = {
            "ä¼˜åŠ¿": "å¯å¤„ç†ä¸å¯è§‚æµ‹æ··æ‚",
            "é™åˆ¶": "éœ€è¦æ»¡è¶³ä¸¥æ ¼æ¡ä»¶çš„ä¸­ä»‹å˜é‡",
            "åº”ç”¨": "ç›¸å¯¹è¾ƒå°‘ï¼Œæ¡ä»¶éš¾æ»¡è¶³",
            "ä¾‹å­": "å¹¿å‘Šâ†’æ€åº¦â†’è´­ä¹°ï¼Œæœ‰ä¸å¯è§‚æµ‹çš„åå¥½"
        }
        
        for key, value in criterion_info.items():
            print(f"{key}: {value}")
        
        return criterion_info

def comprehensive_causal_inference_summary():
    """å› æœæ¨ç†ç»¼åˆæ€»ç»“"""
    print("=== å› æœæ¨ç†ç†è®ºç»¼åˆæ€»ç»“ ===")
    
    summary = {
        "æ ¸å¿ƒæ¦‚å¿µ": {
            "å› æœvsç›¸å…³": "æ–¹å‘æ€§ã€æœºåˆ¶æ€§ã€å¹²é¢„æ•ˆåº”",
            "å› æœå±‚æ¬¡": "å…³è”ã€å¹²é¢„ã€åäº‹å®ä¸‰å±‚",
            "å›¾æ¨¡å‹": "DAGè¡¨ç¤ºå› æœç»“æ„",
            "d-åˆ†ç¦»": "å›¾ä¸­çš„æ¡ä»¶ç‹¬ç«‹å…³ç³»"
        },
        
        "è¯†åˆ«æ–¹æ³•": {
            "åé—¨è°ƒæ•´": "æ§åˆ¶æ··æ‚å˜é‡",
            "å‰é—¨è°ƒæ•´": "åˆ©ç”¨ä¸­ä»‹å˜é‡",
            "å·¥å…·å˜é‡": "å¤–ç”Ÿå˜å¼‚æ¥æº",
            "å›å½’ä¸è¿ç»­": "é˜ˆå€¼é™„è¿‘çš„å‡†å®éªŒ"
        },
        
        "å®éªŒè®¾è®¡": {
            "éšæœºåŒ–å®éªŒ": "é‡‘æ ‡å‡†ï¼Œå†…éƒ¨æ•ˆåº¦é«˜",
            "è‡ªç„¶å®éªŒ": "åˆ©ç”¨å¤–ç”Ÿå˜å¼‚",
            "å‡†å®éªŒ": "å€¾å‘å¾—åˆ†ã€åŒ¹é…",
            "A/Bæµ‹è¯•": "åœ¨çº¿å®éªŒå¹³å°"
        },
        
        "ä¼°è®¡æ–¹æ³•": {
            "å›å½’è°ƒæ•´": "çº¿æ€§å‡è®¾ä¸‹çš„æ§åˆ¶",
            "åŒ¹é…æ–¹æ³•": "å¯»æ‰¾ç›¸ä¼¼å¯¹ç…§ç»„",
            "åŒé‡å·®åˆ†": "æ—¶é—´å’Œç»„åˆ«çš„äº¤äº’",
            "åˆæˆæ§åˆ¶": "æ„é€ åäº‹å®å¯¹ç…§"
        },
        
        "åº”ç”¨é¢†åŸŸ": {
            "ç»æµå­¦": "æ”¿ç­–è¯„ä¼°ã€å¸‚åœºåˆ†æ",
            "åŒ»å­¦": "è¯ç‰©æ•ˆæœã€æ²»ç–—æ–¹æ¡ˆ",
            "ç¤¾ä¼šç§‘å­¦": "æ•™è‚²æ”¿ç­–ã€ç¤¾ä¼šå¹²é¢„",
            "æœºå™¨å­¦ä¹ ": "å…¬å¹³æ€§ã€å¯è§£é‡Šæ€§"
        },
        
        "æŒ‘æˆ˜ä¸é™åˆ¶": {
            "å‡è®¾ä¸¥æ ¼": "ä¸å¯éªŒè¯çš„è¯†åˆ«å‡è®¾",
            "å¤–éƒ¨æ•ˆåº¦": "ç»“æœçš„æ³›åŒ–èƒ½åŠ›",
            "å¤æ‚æ€§": "å¤šé‡æ²»ç–—ã€æ—¶å˜æ··æ‚",
            "æ•°æ®éœ€æ±‚": "é«˜è´¨é‡æ•°æ®è¦æ±‚"
        }
    }
    
    for category, items in summary.items():
        print(f"\n{category}:")
        for key, value in items.items():
            print(f"  {key}: {value}")
    
    return summary

print("å› æœæ¨ç†ç†è®ºæŒ‡å—åŠ è½½å®Œæˆï¼")
```

## å‚è€ƒæ–‡çŒ® ğŸ“š

- Pearl (2009): "Causality: Models, Reasoning and Inference"
- HernÃ¡n & Robins (2020): "Causal Inference: What If"
- Imbens & Rubin (2015): "Causal Inference for Statistics, Social, and Biomedical Sciences"
- Peters, Janzing & SchÃ¶lkopf (2017): "Elements of Causal Inference"

## ä¸‹ä¸€æ­¥å­¦ä¹ 
- [å®éªŒè®¾è®¡](experimental_design.md) - éšæœºåŒ–å®éªŒæ–¹æ³•
- [è§‚å¯Ÿæ€§ç ”ç©¶](observational_studies.md) - å‡†å®éªŒè®¾è®¡
- [å› æœå‘ç°](causal_discovery.md) - ä»æ•°æ®å­¦ä¹ å› æœç»“æ„