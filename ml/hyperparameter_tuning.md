# è¶…å‚æ•°è°ƒä¼˜å®Œå…¨æŒ‡å— ğŸ¯

è¶…å‚æ•°è°ƒä¼˜å°±åƒè°ƒéŸ³å¸ˆè°ƒé’¢ç´ï¼Œæ‰¾åˆ°è®©æ¨¡å‹"éŸ³è‰²"æœ€ç¾çš„å‚æ•°ç»„åˆã€‚æœ¬ç« å°†ä»‹ç»ä»æš´åŠ›æœç´¢åˆ°æ™ºèƒ½ä¼˜åŒ–çš„å„ç§æ–¹æ³•ã€‚

## 1. GridSearchCV - ç½‘æ ¼æœç´¢ ğŸ“Š

### æ ¸å¿ƒæ€æƒ³
éå†æ‰€æœ‰å‚æ•°ç»„åˆï¼Œåƒåœ¨ç½‘æ ¼ä¸Šé€ä¸ªå°è¯•æ¯ä¸ªäº¤å‰ç‚¹ã€‚è™½ç„¶è€—æ—¶ä½†ä¿è¯æ‰¾åˆ°æœ€ä¼˜è§£ï¼ˆåœ¨ç»™å®šèŒƒå›´å†…ï¼‰ã€‚

### å®Œæ•´ä»£ç å®ç°

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification, make_regression
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score
import time
import warnings
warnings.filterwarnings('ignore')

# åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
X_clf, y_clf = make_classification(n_samples=1000, n_features=20, 
                                   n_informative=15, n_redundant=5,
                                   n_classes=2, random_state=42)

X_reg, y_reg = make_regression(n_samples=1000, n_features=20,
                               n_informative=15, noise=10, random_state=42)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_clf, y_clf, test_size=0.2, stratify=y_clf, random_state=42
)

print("=== GridSearchCV ç¤ºä¾‹ ===")

# 1. ç®€å•çš„ç½‘æ ¼æœç´¢
from sklearn.tree import DecisionTreeClassifier

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

# è®¡ç®—æ€»ç»„åˆæ•°
n_combinations = 1
for param, values in param_grid.items():
    n_combinations *= len(values)
print(f"å‚æ•°ç»„åˆæ€»æ•°: {n_combinations}")

# åˆ›å»ºGridSearchCVå¯¹è±¡
dt = DecisionTreeClassifier(random_state=42)
grid_search = GridSearchCV(
    estimator=dt,
    param_grid=param_grid,
    cv=5,  # 5æŠ˜äº¤å‰éªŒè¯
    scoring='accuracy',
    n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    verbose=1  # æ˜¾ç¤ºè¿›åº¦
)

# è®­ç»ƒ
start_time = time.time()
grid_search.fit(X_train, y_train)
grid_time = time.time() - start_time

print(f"\nç½‘æ ¼æœç´¢è€—æ—¶: {grid_time:.2f}ç§’")
print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"æœ€ä½³CVåˆ†æ•°: {grid_search.best_score_:.4f}")

# ä½¿ç”¨æœ€ä½³å‚æ•°çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f}")

# 2. å¯è§†åŒ–æœç´¢ç»“æœ
results_df = pd.DataFrame(grid_search.cv_results_)

# åˆ›å»ºçƒ­åŠ›å›¾æ˜¾ç¤ºä¸åŒå‚æ•°ç»„åˆçš„æ€§èƒ½
pivot_table = results_df.pivot_table(
    values='mean_test_score',
    index='param_max_depth',
    columns='param_min_samples_split'
)

plt.figure(figsize=(10, 6))
sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='YlOrRd')
plt.title('GridSearchCVç»“æœçƒ­åŠ›å›¾')
plt.xlabel('min_samples_split')
plt.ylabel('max_depth')
plt.show()

# 3. å¤šæŒ‡æ ‡è¯„ä¼°
from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score

# å®šä¹‰å¤šä¸ªè¯„åˆ†æŒ‡æ ‡
scoring = {
    'accuracy': 'accuracy',
    'precision': make_scorer(precision_score),
    'recall': make_scorer(recall_score),
    'f1': make_scorer(f1_score)
}

# ä½¿ç”¨å¤šæŒ‡æ ‡çš„GridSearchCV
multi_grid = GridSearchCV(
    estimator=dt,
    param_grid=param_grid,
    cv=5,
    scoring=scoring,
    refit='f1',  # ä½¿ç”¨F1åˆ†æ•°é€‰æ‹©æœ€ä½³æ¨¡å‹
    n_jobs=-1,
    return_train_score=True
)

multi_grid.fit(X_train, y_train)

print("\nå¤šæŒ‡æ ‡è¯„ä¼°ç»“æœ:")
for metric in scoring.keys():
    score = multi_grid.cv_results_[f'mean_test_{metric}'][multi_grid.best_index_]
    print(f"{metric}: {score:.4f}")
```

## 2. RandomizedSearchCV - éšæœºæœç´¢ ğŸ²

### æ ¸å¿ƒæ€æƒ³
éšæœºé‡‡æ ·å‚æ•°ç»„åˆï¼Œç”¨æ›´å°‘çš„å°è¯•æ‰¾åˆ°æ¥è¿‘æœ€ä¼˜çš„è§£ã€‚é€‚åˆå‚æ•°ç©ºé—´å¾ˆå¤§çš„æƒ…å†µã€‚

```python
from scipy import stats

print("\n=== RandomizedSearchCV ç¤ºä¾‹ ===")

# å®šä¹‰è¿ç»­åˆ†å¸ƒçš„å‚æ•°ç©ºé—´
param_distributions = {
    'n_estimators': stats.randint(50, 200),
    'max_depth': stats.randint(3, 20),
    'min_samples_split': stats.randint(2, 20),
    'min_samples_leaf': stats.randint(1, 10),
    'max_features': stats.uniform(0.1, 0.9),  # è¿ç»­å‡åŒ€åˆ†å¸ƒ
    'bootstrap': [True, False]
}

# åˆ›å»ºRandomizedSearchCV
rf = RandomForestClassifier(random_state=42)
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_distributions,
    n_iter=100,  # å°è¯•100ä¸ªéšæœºç»„åˆ
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

# è®­ç»ƒ
start_time = time.time()
random_search.fit(X_train, y_train)
random_time = time.time() - start_time

print(f"\néšæœºæœç´¢è€—æ—¶: {random_time:.2f}ç§’")
print(f"æœ€ä½³å‚æ•°: {random_search.best_params_}")
print(f"æœ€ä½³CVåˆ†æ•°: {random_search.best_score_:.4f}")

# å¯¹æ¯”Gridå’ŒRandomæœç´¢
print(f"\næ—¶é—´å¯¹æ¯”:")
print(f"GridSearchCV: {grid_time:.2f}ç§’ ({n_combinations}ä¸ªç»„åˆ)")
print(f"RandomizedSearchCV: {random_time:.2f}ç§’ (100ä¸ªç»„åˆ)")
print(f"åŠ é€Ÿæ¯”: {grid_time/random_time:.1f}x")

# å¯è§†åŒ–å‚æ•°é‡è¦æ€§
def plot_param_importance(search_cv, top_n=20):
    """ç»˜åˆ¶å‚æ•°ç»„åˆçš„æ€§èƒ½åˆ†å¸ƒ"""
    results = pd.DataFrame(search_cv.cv_results_)
    results = results.sort_values('mean_test_score', ascending=False).head(top_n)
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    params_to_plot = ['param_n_estimators', 'param_max_depth', 
                      'param_min_samples_split', 'param_min_samples_leaf',
                      'param_max_features', 'mean_test_score']
    
    for idx, param in enumerate(params_to_plot):
        ax = axes[idx // 3, idx % 3]
        if param == 'mean_test_score':
            ax.bar(range(top_n), results[param].values)
            ax.set_xlabel('ç»„åˆæ’å')
            ax.set_ylabel('CVåˆ†æ•°')
            ax.set_title('Top 20ç»„åˆçš„åˆ†æ•°')
        else:
            ax.scatter(results[param].values, results['mean_test_score'].values)
            ax.set_xlabel(param.replace('param_', ''))
            ax.set_ylabel('CVåˆ†æ•°')
            ax.set_title(f'{param.replace("param_", "")}å¯¹æ€§èƒ½çš„å½±å“')
    
    plt.tight_layout()
    plt.show()

plot_param_importance(random_search)

# å­¦ä¹ æ›²çº¿ï¼šå‚æ•°æœç´¢çš„æ”¶æ•›
def plot_search_convergence(search_cv):
    """ç»˜åˆ¶æœç´¢è¿‡ç¨‹çš„æ”¶æ•›æ›²çº¿"""
    results = pd.DataFrame(search_cv.cv_results_)
    results = results.sort_values('mean_test_score', ascending=False)
    
    # è®¡ç®—åˆ°ç›®å‰ä¸ºæ­¢çš„æœ€ä½³åˆ†æ•°
    best_scores = []
    current_best = -np.inf
    for score in results['mean_test_score'].values:
        if score > current_best:
            current_best = score
        best_scores.append(current_best)
    
    plt.figure(figsize=(10, 6))
    plt.plot(range(len(best_scores)), best_scores, 'b-', linewidth=2)
    plt.xlabel('è¯„ä¼°çš„å‚æ•°ç»„åˆæ•°')
    plt.ylabel('æœ€ä½³CVåˆ†æ•°')
    plt.title('éšæœºæœç´¢æ”¶æ•›æ›²çº¿')
    plt.grid(True, alpha=0.3)
    plt.show()

plot_search_convergence(random_search)
```

## 3. è´å¶æ–¯ä¼˜åŒ– - æ™ºèƒ½æœç´¢ ğŸ§ 

### æ ¸å¿ƒæ€æƒ³
ä½¿ç”¨ä¹‹å‰çš„è¯„ä¼°ç»“æœæ¥æŒ‡å¯¼ä¸‹ä¸€æ¬¡å°è¯•ï¼Œåƒä¸€ä¸ªä¼šå­¦ä¹ çš„æœç´¢ç®—æ³•ã€‚

```python
# éœ€è¦å®‰è£…: pip install scikit-optimize
try:
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer, Categorical
    from skopt.utils import use_named_args
    from skopt import gp_minimize
    
    print("\n=== è´å¶æ–¯ä¼˜åŒ– ===")
    
    # å®šä¹‰æœç´¢ç©ºé—´
    search_spaces = {
        'n_estimators': Integer(50, 200),
        'max_depth': Integer(3, 20),
        'min_samples_split': Integer(2, 20),
        'min_samples_leaf': Integer(1, 10),
        'max_features': Real(0.1, 0.9),
        'bootstrap': Categorical([True, False])
    }
    
    # åˆ›å»ºè´å¶æ–¯æœç´¢
    bayes_search = BayesSearchCV(
        estimator=RandomForestClassifier(random_state=42),
        search_spaces=search_spaces,
        n_iter=50,  # æ¯”éšæœºæœç´¢æ›´å°‘çš„è¿­ä»£
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        random_state=42
    )
    
    # è®­ç»ƒ
    start_time = time.time()
    bayes_search.fit(X_train, y_train)
    bayes_time = time.time() - start_time
    
    print(f"\nè´å¶æ–¯ä¼˜åŒ–è€—æ—¶: {bayes_time:.2f}ç§’")
    print(f"æœ€ä½³å‚æ•°: {bayes_search.best_params_}")
    print(f"æœ€ä½³CVåˆ†æ•°: {bayes_search.best_score_:.4f}")
    
    # ä¸‰ç§æ–¹æ³•å¯¹æ¯”
    comparison_data = {
        'æ–¹æ³•': ['Grid Search', 'Random Search', 'Bayesian Optimization'],
        'è€—æ—¶(ç§’)': [grid_time, random_time, bayes_time],
        'å°è¯•æ¬¡æ•°': [n_combinations, 100, 50],
        'CVåˆ†æ•°': [grid_search.best_score_, 
                  random_search.best_score_, 
                  bayes_search.best_score_]
    }
    
    comparison_df = pd.DataFrame(comparison_data)
    print("\nä¸‰ç§è°ƒå‚æ–¹æ³•å¯¹æ¯”:")
    print(comparison_df)
    
    # å¯è§†åŒ–å¯¹æ¯”
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # è€—æ—¶å¯¹æ¯”
    axes[0].bar(comparison_df['æ–¹æ³•'], comparison_df['è€—æ—¶(ç§’)'])
    axes[0].set_ylabel('è€—æ—¶(ç§’)')
    axes[0].set_title('è¿è¡Œæ—¶é—´å¯¹æ¯”')
    
    # å°è¯•æ¬¡æ•°å¯¹æ¯”
    axes[1].bar(comparison_df['æ–¹æ³•'], comparison_df['å°è¯•æ¬¡æ•°'])
    axes[1].set_ylabel('å‚æ•°ç»„åˆæ•°')
    axes[1].set_title('å°è¯•æ¬¡æ•°å¯¹æ¯”')
    
    # CVåˆ†æ•°å¯¹æ¯”
    axes[2].bar(comparison_df['æ–¹æ³•'], comparison_df['CVåˆ†æ•°'])
    axes[2].set_ylabel('CVåˆ†æ•°')
    axes[2].set_title('æœ€ä½³åˆ†æ•°å¯¹æ¯”')
    axes[2].set_ylim([min(comparison_df['CVåˆ†æ•°']) * 0.95, 
                      max(comparison_df['CVåˆ†æ•°']) * 1.02])
    
    plt.tight_layout()
    plt.show()
    
except ImportError:
    print("\nè´å¶æ–¯ä¼˜åŒ–éœ€è¦å®‰è£…scikit-optimize:")
    print("pip install scikit-optimize")
```

## 4. Optuna - æ–°ä¸€ä»£ä¼˜åŒ–æ¡†æ¶ ğŸš€

```python
# éœ€è¦å®‰è£…: pip install optuna
try:
    import optuna
    from optuna import Trial
    from optuna.samplers import TPESampler
    
    print("\n=== Optuna é«˜çº§ä¼˜åŒ– ===")
    
    def objective(trial: Trial):
        """å®šä¹‰ä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
        # å»ºè®®è¶…å‚æ•°
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 200),
            'max_depth': trial.suggest_int('max_depth', 3, 20),
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
            'max_features': trial.suggest_float('max_features', 0.1, 0.9),
            'bootstrap': trial.suggest_categorical('bootstrap', [True, False])
        }
        
        # åˆ›å»ºæ¨¡å‹
        model = RandomForestClassifier(**params, random_state=42)
        
        # äº¤å‰éªŒè¯
        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        
        return scores.mean()
    
    # åˆ›å»ºstudy
    study = optuna.create_study(
        direction='maximize',  # æœ€å¤§åŒ–å‡†ç¡®ç‡
        sampler=TPESampler(seed=42)  # ä½¿ç”¨TPEé‡‡æ ·å™¨
    )
    
    # ä¼˜åŒ–
    start_time = time.time()
    study.optimize(objective, n_trials=50, show_progress_bar=True)
    optuna_time = time.time() - start_time
    
    print(f"\nOptunaä¼˜åŒ–è€—æ—¶: {optuna_time:.2f}ç§’")
    print(f"æœ€ä½³å‚æ•°: {study.best_params}")
    print(f"æœ€ä½³åˆ†æ•°: {study.best_value:.4f}")
    
    # å¯è§†åŒ–ä¼˜åŒ–å†å²
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # ä¼˜åŒ–å†å²
    trials_df = study.trials_dataframe()
    axes[0].plot(trials_df.index, trials_df['value'], 'b-', alpha=0.5)
    axes[0].scatter(study.best_trial.number, study.best_value, 
                   color='red', s=100, zorder=5)
    axes[0].set_xlabel('Trial')
    axes[0].set_ylabel('Objective Value')
    axes[0].set_title('Optunaä¼˜åŒ–å†å²')
    axes[0].grid(True, alpha=0.3)
    
    # å‚æ•°é‡è¦æ€§
    importances = optuna.importance.get_param_importances(study)
    params = list(importances.keys())
    values = list(importances.values())
    
    axes[1].barh(params, values)
    axes[1].set_xlabel('é‡è¦æ€§')
    axes[1].set_title('å‚æ•°é‡è¦æ€§ï¼ˆOptunaï¼‰')
    
    plt.tight_layout()
    plt.show()
    
except ImportError:
    print("\nOptunaéœ€è¦å®‰è£…:")
    print("pip install optuna")
```

## 5. å®æˆ˜æ¡ˆä¾‹ï¼šå¤šæ¨¡å‹è”åˆè°ƒä¼˜

```python
print("\n=== å®æˆ˜ï¼šå¤šæ¨¡å‹è”åˆè°ƒä¼˜ ===")

from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
import xgboost as xgb

# å®šä¹‰å¤šä¸ªæ¨¡å‹å’Œå®ƒä»¬çš„å‚æ•°ç©ºé—´
models_and_params = {
    'RandomForest': {
        'model': RandomForestClassifier(random_state=42),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5]
        }
    },
    'SVM': {
        'model': SVC(random_state=42, probability=True),
        'params': {
            'C': [0.1, 1, 10],
            'kernel': ['rbf', 'poly'],
            'gamma': ['scale', 'auto']
        }
    },
    'XGBoost': {
        'model': xgb.XGBClassifier(random_state=42, use_label_encoder=False,
                                   eval_metric='logloss'),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1]
        }
    }
}

# å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œè°ƒä¼˜
best_models = {}
results_summary = []

for name, config in models_and_params.items():
    print(f"\nè°ƒä¼˜ {name}...")
    
    grid = GridSearchCV(
        estimator=config['model'],
        param_grid=config['params'],
        cv=5,
        scoring='accuracy',
        n_jobs=-1
    )
    
    grid.fit(X_train, y_train)
    best_models[name] = grid.best_estimator_
    
    # æµ‹è¯•é›†æ€§èƒ½
    y_pred = grid.best_estimator_.predict(X_test)
    test_acc = accuracy_score(y_test, y_pred)
    
    results_summary.append({
        'æ¨¡å‹': name,
        'CVåˆ†æ•°': grid.best_score_,
        'æµ‹è¯•åˆ†æ•°': test_acc,
        'æœ€ä½³å‚æ•°': grid.best_params_
    })
    
    print(f"  æœ€ä½³CVåˆ†æ•°: {grid.best_score_:.4f}")
    print(f"  æµ‹è¯•é›†åˆ†æ•°: {test_acc:.4f}")

# ç»“æœæ±‡æ€»
results_df = pd.DataFrame(results_summary)
print("\n=== æ‰€æœ‰æ¨¡å‹è°ƒä¼˜ç»“æœ ===")
print(results_df[['æ¨¡å‹', 'CVåˆ†æ•°', 'æµ‹è¯•åˆ†æ•°']])

# é›†æˆæœ€ä½³æ¨¡å‹
from sklearn.ensemble import VotingClassifier

ensemble = VotingClassifier(
    estimators=[(name, model) for name, model in best_models.items()],
    voting='soft'
)

ensemble.fit(X_train, y_train)
ensemble_pred = ensemble.predict(X_test)
ensemble_acc = accuracy_score(y_test, ensemble_pred)

print(f"\né›†æˆæ¨¡å‹å‡†ç¡®ç‡: {ensemble_acc:.4f}")

# å¯è§†åŒ–å¯¹æ¯”
plt.figure(figsize=(10, 6))
models = results_df['æ¨¡å‹'].tolist() + ['Ensemble']
cv_scores = results_df['CVåˆ†æ•°'].tolist() + [ensemble_acc]
test_scores = results_df['æµ‹è¯•åˆ†æ•°'].tolist() + [ensemble_acc]

x = np.arange(len(models))
width = 0.35

plt.bar(x - width/2, cv_scores, width, label='CVåˆ†æ•°', alpha=0.8)
plt.bar(x + width/2, test_scores, width, label='æµ‹è¯•åˆ†æ•°', alpha=0.8)

plt.xlabel('æ¨¡å‹')
plt.ylabel('å‡†ç¡®ç‡')
plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”')
plt.xticks(x, models)
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

## 6. é«˜çº§æŠ€å·§ï¼šè‡ªé€‚åº”è°ƒå‚ç­–ç•¥

```python
class AdaptiveHyperparameterTuner:
    """è‡ªé€‚åº”è¶…å‚æ•°è°ƒä¼˜å™¨"""
    
    def __init__(self, model_class, initial_params, param_ranges):
        self.model_class = model_class
        self.initial_params = initial_params
        self.param_ranges = param_ranges
        self.history = []
        
    def coarse_search(self, X, y, cv=5):
        """ç²—æœç´¢ï¼šå¤§èŒƒå›´å¿«é€Ÿæœç´¢"""
        print("Phase 1: ç²—æœç´¢...")
        
        # åˆ›å»ºç²—ç²’åº¦å‚æ•°ç½‘æ ¼
        coarse_grid = {}
        for param, range_vals in self.param_ranges.items():
            if isinstance(range_vals, list):
                # ç¦»æ•£å‚æ•°
                coarse_grid[param] = range_vals[::2]  # æ¯éš”ä¸€ä¸ªå–ä¸€ä¸ª
            else:
                # è¿ç»­å‚æ•°
                min_val, max_val = range_vals
                coarse_grid[param] = np.linspace(min_val, max_val, 5)
        
        # æ‰§è¡Œç½‘æ ¼æœç´¢
        model = self.model_class(**self.initial_params)
        grid = GridSearchCV(model, coarse_grid, cv=cv, n_jobs=-1)
        grid.fit(X, y)
        
        self.coarse_best_params = grid.best_params_
        self.coarse_best_score = grid.best_score_
        
        print(f"  ç²—æœç´¢æœ€ä½³åˆ†æ•°: {self.coarse_best_score:.4f}")
        return self.coarse_best_params
    
    def fine_search(self, X, y, cv=5):
        """ç»†æœç´¢ï¼šåœ¨æœ€ä½³å‚æ•°é™„è¿‘ç²¾ç»†æœç´¢"""
        print("Phase 2: ç»†æœç´¢...")
        
        # åˆ›å»ºç»†ç²’åº¦å‚æ•°ç½‘æ ¼
        fine_grid = {}
        for param, best_val in self.coarse_best_params.items():
            range_vals = self.param_ranges[param]
            
            if isinstance(range_vals, list):
                # ç¦»æ•£å‚æ•°ï¼šé€‰æ‹©é‚»è¿‘å€¼
                idx = range_vals.index(best_val)
                start_idx = max(0, idx - 1)
                end_idx = min(len(range_vals), idx + 2)
                fine_grid[param] = range_vals[start_idx:end_idx]
            else:
                # è¿ç»­å‚æ•°ï¼šåœ¨æœ€ä½³å€¼é™„è¿‘æœç´¢
                min_val, max_val = range_vals
                delta = (max_val - min_val) * 0.1
                fine_min = max(min_val, best_val - delta)
                fine_max = min(max_val, best_val + delta)
                fine_grid[param] = np.linspace(fine_min, fine_max, 5)
        
        # æ‰§è¡Œç»†æœç´¢
        model = self.model_class(**self.initial_params)
        grid = GridSearchCV(model, fine_grid, cv=cv, n_jobs=-1)
        grid.fit(X, y)
        
        self.fine_best_params = grid.best_params_
        self.fine_best_score = grid.best_score_
        
        print(f"  ç»†æœç´¢æœ€ä½³åˆ†æ•°: {self.fine_best_score:.4f}")
        return self.fine_best_params
    
    def adaptive_search(self, X, y, cv=5):
        """å®Œæ•´çš„è‡ªé€‚åº”æœç´¢æµç¨‹"""
        # ç²—æœç´¢
        coarse_params = self.coarse_search(X, y, cv)
        
        # ç»†æœç´¢
        fine_params = self.fine_search(X, y, cv)
        
        # è¿”å›æœ€ç»ˆæœ€ä½³å‚æ•°
        return fine_params, self.fine_best_score

# ä½¿ç”¨ç¤ºä¾‹
print("\n=== è‡ªé€‚åº”è¶…å‚æ•°è°ƒä¼˜ ===")

tuner = AdaptiveHyperparameterTuner(
    model_class=RandomForestClassifier,
    initial_params={'random_state': 42},
    param_ranges={
        'n_estimators': (50, 300),
        'max_depth': (3, 20),
        'min_samples_split': (2, 20),
        'min_samples_leaf': (1, 10)
    }
)

best_params, best_score = tuner.adaptive_search(X_train, y_train)
print(f"\næœ€ç»ˆæœ€ä½³å‚æ•°: {best_params}")
print(f"æœ€ç»ˆæœ€ä½³åˆ†æ•°: {best_score:.4f}")
```

## 7. å®ç”¨å·¥å…·å‡½æ•°

```python
def plot_validation_curve(model, X, y, param_name, param_range, cv=5):
    """ç»˜åˆ¶éªŒè¯æ›²çº¿"""
    from sklearn.model_selection import validation_curve
    
    train_scores, val_scores = validation_curve(
        model, X, y, param_name=param_name,
        param_range=param_range, cv=cv, n_jobs=-1
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.plot(param_range, train_mean, 'b-', label='è®­ç»ƒåˆ†æ•°')
    plt.fill_between(param_range, train_mean - train_std,
                     train_mean + train_std, alpha=0.1, color='b')
    plt.plot(param_range, val_mean, 'r-', label='éªŒè¯åˆ†æ•°')
    plt.fill_between(param_range, val_mean - val_std,
                     val_mean + val_std, alpha=0.1, color='r')
    
    plt.xlabel(param_name)
    plt.ylabel('åˆ†æ•°')
    plt.title(f'éªŒè¯æ›²çº¿: {param_name}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

# ç¤ºä¾‹
print("\n=== éªŒè¯æ›²çº¿åˆ†æ ===")
plot_validation_curve(
    RandomForestClassifier(random_state=42),
    X_train, y_train,
    'n_estimators',
    [10, 50, 100, 150, 200, 250, 300]
)

def get_param_importance(model, X, y, param_ranges, n_iter=20):
    """è¯„ä¼°å‚æ•°é‡è¦æ€§"""
    from sklearn.model_selection import RandomizedSearchCV
    
    random_search = RandomizedSearchCV(
        model, param_ranges, n_iter=n_iter,
        cv=5, n_jobs=-1, random_state=42
    )
    random_search.fit(X, y)
    
    results = pd.DataFrame(random_search.cv_results_)
    
    # è®¡ç®—æ¯ä¸ªå‚æ•°çš„é‡è¦æ€§
    importances = {}
    for param in param_ranges.keys():
        param_col = f'param_{param}'
        if param_col in results.columns:
            # è®¡ç®—å‚æ•°å€¼ä¸åˆ†æ•°çš„ç›¸å…³æ€§
            correlation = results[[param_col, 'mean_test_score']].corr().iloc[0, 1]
            importances[param] = abs(correlation)
    
    return importances

# ç¤ºä¾‹
param_ranges = {
    'n_estimators': stats.randint(50, 200),
    'max_depth': stats.randint(3, 20),
    'min_samples_split': stats.randint(2, 20)
}

importances = get_param_importance(
    RandomForestClassifier(random_state=42),
    X_train, y_train,
    param_ranges
)

print("\nå‚æ•°é‡è¦æ€§:")
for param, importance in sorted(importances.items(), 
                               key=lambda x: x[1], reverse=True):
    print(f"  {param}: {importance:.3f}")
```

## æœ€ä½³å®è·µå»ºè®®

### 1. è°ƒå‚æµç¨‹
1. **å»ºç«‹åŸºçº¿**ï¼šä½¿ç”¨é»˜è®¤å‚æ•°
2. **å•å‚æ•°åˆ†æ**ï¼šç†è§£æ¯ä¸ªå‚æ•°çš„å½±å“
3. **ç²—è°ƒ**ï¼šå¤§èŒƒå›´å¿«é€Ÿæœç´¢
4. **ç»†è°ƒ**ï¼šåœ¨æœ€ä½³åŒºåŸŸç²¾ç»†æœç´¢
5. **éªŒè¯**ï¼šç¡®ä¿æ²¡æœ‰è¿‡æ‹Ÿåˆ

### 2. é€‰æ‹©è°ƒä¼˜æ–¹æ³•
- **å‚æ•°å°‘(<10)**: GridSearchCV
- **å‚æ•°ä¸­ç­‰(10-20)**: RandomizedSearchCV
- **å‚æ•°å¤š(>20)**: è´å¶æ–¯ä¼˜åŒ–æˆ–Optuna
- **è®¡ç®—èµ„æºæœ‰é™**: éšæœºæœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–

### 3. å¸¸è§é™·é˜±
- åœ¨æµ‹è¯•é›†ä¸Šè°ƒå‚ï¼ˆæ•°æ®æ³„éœ²ï¼‰
- å¿½è§†è®¡ç®—æˆæœ¬
- è¿‡åº¦è°ƒä¼˜å¯¼è‡´è¿‡æ‹Ÿåˆ
- ä¸è€ƒè™‘å‚æ•°é—´çš„ç›¸äº’ä½œç”¨

## ä¸‹ä¸€æ­¥å­¦ä¹ 
- [ç‰¹å¾å·¥ç¨‹](feature_engineering.md) - å¥½ç‰¹å¾æ¯”è°ƒå‚æ›´é‡è¦
- [æ¨¡å‹è¯„ä¼°](evaluation.md) - æ­£ç¡®è¯„ä¼°è°ƒå‚æ•ˆæœ
- [AutoML](automl.md) - è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ 