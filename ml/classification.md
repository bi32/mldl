# åˆ†ç±»ç®—æ³•è¯¦è§£ ğŸ¯

åˆ†ç±»å°±åƒç»™äº‹ç‰©è´´æ ‡ç­¾ï¼Œæ¯”å¦‚åˆ¤æ–­é‚®ä»¶æ˜¯å¦åƒåœ¾é‚®ä»¶ã€è¯Šæ–­ç–¾ç—…ã€è¯†åˆ«å›¾ç‰‡ä¸­çš„ç‰©ä½“ã€‚

## 1. é€»è¾‘å›å½’ (Logistic Regression)

### æ ¸å¿ƒæ€æƒ³
è™½ç„¶å«"å›å½’"ï¼Œä½†å®ƒæ˜¯åˆ†ç±»ç®—æ³•ï¼å®ƒç”¨Så‹æ›²çº¿ï¼ˆSigmoidï¼‰æŠŠçº¿æ€§å›å½’çš„è¾“å‡ºå‹ç¼©åˆ°0-1ä¹‹é—´ï¼Œè¡¨ç¤ºæ¦‚ç‡ã€‚

### å®Œæ•´ä»£ç å®ç°

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, confusion_matrix,
                           roc_curve, classification_report)

# åˆ›å»ºäºŒåˆ†ç±»æ•°æ®é›†
from sklearn.datasets import make_classification

X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    n_classes=2,
    weights=[0.7, 0.3],  # ç±»åˆ«ä¸å¹³è¡¡
    random_state=42
)

# è½¬æ¢ä¸ºDataFrame
feature_names = [f'ç‰¹å¾_{i+1}' for i in range(20)]
df = pd.DataFrame(X, columns=feature_names)
df['æ ‡ç­¾'] = y

print("æ•°æ®é›†ä¿¡æ¯:")
print(f"æ ·æœ¬æ•°: {len(df)}")
print(f"ç‰¹å¾æ•°: {len(feature_names)}")
print(f"ç±»åˆ«åˆ†å¸ƒ:\n{df['æ ‡ç­¾'].value_counts()}")

# æ•°æ®é¢„å¤„ç†
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
log_reg = LogisticRegression(random_state=42, max_iter=1000)
log_reg.fit(X_train, y_train)

# é¢„æµ‹
y_pred = log_reg.predict(X_test)
y_pred_proba = log_reg.predict_proba(X_test)[:, 1]

# è¯„ä¼°æ¨¡å‹
def evaluate_model(y_true, y_pred, y_pred_proba=None):
    """å…¨é¢è¯„ä¼°åˆ†ç±»æ¨¡å‹"""
    metrics = {
        'å‡†ç¡®ç‡': accuracy_score(y_true, y_pred),
        'ç²¾ç¡®ç‡': precision_score(y_true, y_pred),
        'å¬å›ç‡': recall_score(y_true, y_pred),
        'F1åˆ†æ•°': f1_score(y_true, y_pred)
    }
    
    if y_pred_proba is not None:
        metrics['AUC'] = roc_auc_score(y_true, y_pred_proba)
    
    return metrics

metrics = evaluate_model(y_test, y_pred, y_pred_proba)
print("\næ¨¡å‹è¯„ä¼°æŒ‡æ ‡:")
for metric, value in metrics.items():
    print(f"{metric}: {value:.4f}")

# å¯è§†åŒ–
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# 1. æ··æ·†çŸ©é˜µ
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])
axes[0, 0].set_title('æ··æ·†çŸ©é˜µ')
axes[0, 0].set_xlabel('é¢„æµ‹å€¼')
axes[0, 0].set_ylabel('çœŸå®å€¼')

# 2. ROCæ›²çº¿
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
axes[0, 1].plot(fpr, tpr, 'b-', label=f'AUC = {metrics["AUC"]:.3f}')
axes[0, 1].plot([0, 1], [0, 1], 'r--')
axes[0, 1].set_xlabel('å‡é˜³æ€§ç‡')
axes[0, 1].set_ylabel('çœŸé˜³æ€§ç‡')
axes[0, 1].set_title('ROCæ›²çº¿')
axes[0, 1].legend()

# 3. ç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    'ç‰¹å¾': feature_names,
    'ç³»æ•°': log_reg.coef_[0]
}).sort_values('ç³»æ•°', key=abs, ascending=False).head(10)

axes[0, 2].barh(range(10), feature_importance['ç³»æ•°'].values)
axes[0, 2].set_yticks(range(10))
axes[0, 2].set_yticklabels(feature_importance['ç‰¹å¾'].values)
axes[0, 2].set_xlabel('ç³»æ•°å€¼')
axes[0, 2].set_title('Top 10 é‡è¦ç‰¹å¾')

# 4. é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
axes[1, 0].hist(y_pred_proba[y_test == 0], alpha=0.5, 
                label='ç±»åˆ«0', bins=20, color='blue')
axes[1, 0].hist(y_pred_proba[y_test == 1], alpha=0.5, 
                label='ç±»åˆ«1', bins=20, color='red')
axes[1, 0].set_xlabel('é¢„æµ‹æ¦‚ç‡')
axes[1, 0].set_ylabel('é¢‘æ•°')
axes[1, 0].set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')
axes[1, 0].legend()

# 5. é˜ˆå€¼å¯¹æ€§èƒ½çš„å½±å“
thresholds_test = np.linspace(0, 1, 100)
precisions = []
recalls = []

for threshold in thresholds_test:
    y_pred_threshold = (y_pred_proba >= threshold).astype(int)
    precisions.append(precision_score(y_test, y_pred_threshold, zero_division=0))
    recalls.append(recall_score(y_test, y_pred_threshold, zero_division=0))

axes[1, 1].plot(thresholds_test, precisions, label='ç²¾ç¡®ç‡')
axes[1, 1].plot(thresholds_test, recalls, label='å¬å›ç‡')
axes[1, 1].set_xlabel('é˜ˆå€¼')
axes[1, 1].set_ylabel('åˆ†æ•°')
axes[1, 1].set_title('é˜ˆå€¼å¯¹æ€§èƒ½çš„å½±å“')
axes[1, 1].legend()

# 6. å­¦ä¹ æ›²çº¿
from sklearn.model_selection import learning_curve

train_sizes, train_scores, val_scores = learning_curve(
    LogisticRegression(random_state=42, max_iter=1000),
    X_scaled, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)
)

axes[1, 2].plot(train_sizes, np.mean(train_scores, axis=1), 
                'o-', label='è®­ç»ƒåˆ†æ•°')
axes[1, 2].plot(train_sizes, np.mean(val_scores, axis=1), 
                'o-', label='éªŒè¯åˆ†æ•°')
axes[1, 2].set_xlabel('è®­ç»ƒæ ·æœ¬æ•°')
axes[1, 2].set_ylabel('å‡†ç¡®ç‡')
axes[1, 2].set_title('å­¦ä¹ æ›²çº¿')
axes[1, 2].legend()

plt.tight_layout()
plt.show()

# å¤šåˆ†ç±»é€»è¾‘å›å½’
print("\n=== å¤šåˆ†ç±»é€»è¾‘å›å½’ ===")

# åˆ›å»ºå¤šåˆ†ç±»æ•°æ®
X_multi, y_multi = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_classes=4,
    random_state=42
)

X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(
    X_multi, y_multi, test_size=0.2, stratify=y_multi, random_state=42
)

# è®­ç»ƒå¤šåˆ†ç±»æ¨¡å‹
log_reg_multi = LogisticRegression(
    multi_class='multinomial',  # ä½¿ç”¨softmax
    solver='lbfgs',
    random_state=42,
    max_iter=1000
)
log_reg_multi.fit(X_train_m, y_train_m)

# é¢„æµ‹
y_pred_m = log_reg_multi.predict(X_test_m)
y_pred_proba_m = log_reg_multi.predict_proba(X_test_m)

# è¯„ä¼°
print(f"å¤šåˆ†ç±»å‡†ç¡®ç‡: {accuracy_score(y_test_m, y_pred_m):.4f}")
print("\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test_m, y_pred_m, 
                           target_names=[f'ç±»åˆ«{i}' for i in range(4)]))

# æ··æ·†çŸ©é˜µ
plt.figure(figsize=(8, 6))
cm_multi = confusion_matrix(y_test_m, y_pred_m)
sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues')
plt.title('å¤šåˆ†ç±»æ··æ·†çŸ©é˜µ')
plt.xlabel('é¢„æµ‹ç±»åˆ«')
plt.ylabel('çœŸå®ç±»åˆ«')
plt.show()
```

## 2. æ”¯æŒå‘é‡æœº (SVM)

### æ ¸å¿ƒæ€æƒ³
SVMå¯»æ‰¾ä¸€ä¸ªæœ€ä¼˜è¶…å¹³é¢ï¼Œä½¿å¾—ä¸¤ç±»æ•°æ®ç‚¹ä¹‹é—´çš„é—´éš”æœ€å¤§åŒ–ã€‚å°±åƒåœ¨ä¸¤ç¾¤äººä¹‹é—´ç”»ä¸€æ¡çº¿ï¼Œè®©çº¿ä¸¤è¾¹çš„ç©ºé—´æœ€å¤§ã€‚

```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings('ignore')

# åˆ›å»ºéçº¿æ€§å¯åˆ†æ•°æ®
from sklearn.datasets import make_moons, make_circles

# ç”Ÿæˆæœˆäº®å½¢æ•°æ®
X_moon, y_moon = make_moons(n_samples=500, noise=0.15, random_state=42)

# æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_moon_scaled = scaler.fit_transform(X_moon)

# è®­ç»ƒä¸åŒæ ¸å‡½æ•°çš„SVM
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

for idx, kernel in enumerate(kernels):
    ax = axes[idx // 2, idx % 2]
    
    # è®­ç»ƒSVM
    if kernel == 'poly':
        svm = SVC(kernel=kernel, degree=3, random_state=42)
    else:
        svm = SVC(kernel=kernel, random_state=42)
    
    svm.fit(X_moon_scaled, y_moon)
    
    # åˆ›å»ºç½‘æ ¼ç”¨äºå†³ç­–è¾¹ç•Œ
    h = 0.02
    x_min, x_max = X_moon_scaled[:, 0].min() - 1, X_moon_scaled[:, 0].max() + 1
    y_min, y_max = X_moon_scaled[:, 1].min() - 1, X_moon_scaled[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    
    # é¢„æµ‹ç½‘æ ¼ç‚¹
    Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    ax.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)
    ax.scatter(X_moon_scaled[:, 0], X_moon_scaled[:, 1], 
               c=y_moon, cmap=plt.cm.RdYlBu, edgecolor='black')
    ax.set_title(f'SVM ({kernel} kernel)')
    ax.set_xlabel('ç‰¹å¾1')
    ax.set_ylabel('ç‰¹å¾2')

plt.tight_layout()
plt.show()

# SVMå‚æ•°è°ƒä¼˜
print("=== SVMå‚æ•°è°ƒä¼˜ ===")

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],
    'kernel': ['rbf', 'poly', 'sigmoid']
}

# ç½‘æ ¼æœç´¢
svm_base = SVC(random_state=42)
grid_search = GridSearchCV(
    svm_base, param_grid, cv=5, 
    scoring='accuracy', n_jobs=-1
)

# ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†
X_large, y_large = make_classification(
    n_samples=1000, n_features=20, n_informative=15,
    n_redundant=5, random_state=42
)
X_large_scaled = StandardScaler().fit_transform(X_large)

X_train, X_test, y_train, y_test = train_test_split(
    X_large_scaled, y_large, test_size=0.2, random_state=42
)

grid_search.fit(X_train, y_train)

print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"æœ€ä½³äº¤å‰éªŒè¯åˆ†æ•°: {grid_search.best_score_:.4f}")

# ä½¿ç”¨æœ€ä½³å‚æ•°çš„æ¨¡å‹
best_svm = grid_search.best_estimator_
y_pred = best_svm.predict(X_test)

print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.4f}")

# SVMçš„æ”¯æŒå‘é‡
print(f"\næ”¯æŒå‘é‡æ•°é‡: {len(best_svm.support_)}")
print(f"æ€»è®­ç»ƒæ ·æœ¬æ•°: {len(X_train)}")
print(f"æ”¯æŒå‘é‡æ¯”ä¾‹: {len(best_svm.support_) / len(X_train):.2%}")
```

## 3. æœ´ç´ è´å¶æ–¯ (Naive Bayes)

### æ ¸å¿ƒæ€æƒ³
åŸºäºè´å¶æ–¯å®šç†ï¼Œå‡è®¾ç‰¹å¾ä¹‹é—´ç›¸äº’ç‹¬ç«‹ã€‚å°±åƒåƒåœ¾é‚®ä»¶è¿‡æ»¤å™¨ï¼Œé€šè¿‡ç»Ÿè®¡è¯é¢‘æ¥åˆ¤æ–­é‚®ä»¶ç±»åˆ«ã€‚

```python
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

# 1. é«˜æ–¯æœ´ç´ è´å¶æ–¯ï¼ˆè¿ç»­ç‰¹å¾ï¼‰
print("=== é«˜æ–¯æœ´ç´ è´å¶æ–¯ ===")

# ä½¿ç”¨ä¹‹å‰çš„æ•°æ®
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_gnb = gnb.predict(X_test)

print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred_gnb):.4f}")

# 2. å¤šé¡¹å¼æœ´ç´ è´å¶æ–¯ï¼ˆæ–‡æœ¬åˆ†ç±»ï¼‰
print("\n=== æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹ ===")

# åˆ›å»ºç¤ºä¾‹æ–‡æœ¬æ•°æ®
texts = [
    "å…è´¹èµ¢å–iPhoneï¼Œç‚¹å‡»è¿™é‡Œï¼",
    "æ­å–œæ‚¨ä¸­å¥–äº†ï¼Œè¯·æä¾›é“¶è¡Œè´¦å·",
    "ä¼šè®®å®‰æ’åœ¨æ˜å¤©ä¸‹åˆ3ç‚¹",
    "é¡¹ç›®è¿›åº¦æŠ¥å‘Šå·²å‘é€",
    "é™æ—¶ä¼˜æƒ ï¼Œä¹°ä¸€é€ä¸€",
    "è¯·æŸ¥æ”¶é™„ä»¶ä¸­çš„åˆåŒ",
    "æ‚¨çš„åŒ…è£¹å·²å‘è´§",
    "ç´§æ€¥ï¼è´¦æˆ·å³å°†åˆ°æœŸ",
    "å­£åº¦è´¢åŠ¡æŠ¥è¡¨åˆ†æ",
    "å›¢é˜Ÿå»ºè®¾æ´»åŠ¨é€šçŸ¥"
]

labels = [1, 1, 0, 0, 1, 0, 0, 1, 0, 0]  # 1: åƒåœ¾é‚®ä»¶, 0: æ­£å¸¸é‚®ä»¶

# æ‰©å±•æ•°æ®é›†
texts_extended = texts * 50  # é‡å¤ä»¥å¢åŠ æ ·æœ¬
labels_extended = labels * 50
# æ·»åŠ éšæœºæ€§
np.random.seed(42)
shuffle_idx = np.random.permutation(len(texts_extended))
texts_extended = [texts_extended[i] for i in shuffle_idx]
labels_extended = [labels_extended[i] for i in shuffle_idx]

# æ–‡æœ¬å‘é‡åŒ–
vectorizer = CountVectorizer()
X_text = vectorizer.fit_transform(texts_extended)

# åˆ’åˆ†æ•°æ®
X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(
    X_text, labels_extended, test_size=0.2, random_state=42
)

# è®­ç»ƒå¤šé¡¹å¼æœ´ç´ è´å¶æ–¯
mnb = MultinomialNB()
mnb.fit(X_train_text, y_train_text)

# é¢„æµ‹
y_pred_text = mnb.predict(X_test_text)
print(f"æ–‡æœ¬åˆ†ç±»å‡†ç¡®ç‡: {accuracy_score(y_test_text, y_pred_text):.4f}")

# æµ‹è¯•æ–°æ–‡æœ¬
new_texts = [
    "æ­å–œè·å¾—ç™¾ä¸‡å¤§å¥–",
    "æ˜å¤©çš„ä¼šè®®è®®ç¨‹",
    "é™æ—¶æŠ˜æ‰£æ´»åŠ¨"
]

new_texts_vec = vectorizer.transform(new_texts)
predictions = mnb.predict(new_texts_vec)
probabilities = mnb.predict_proba(new_texts_vec)

print("\næ–°æ–‡æœ¬é¢„æµ‹ç»“æœ:")
for text, pred, prob in zip(new_texts, predictions, probabilities):
    label = "åƒåœ¾é‚®ä»¶" if pred == 1 else "æ­£å¸¸é‚®ä»¶"
    confidence = max(prob) * 100
    print(f"æ–‡æœ¬: {text}")
    print(f"  é¢„æµ‹: {label} (ç½®ä¿¡åº¦: {confidence:.1f}%)")

# 3. æ¯”è¾ƒä¸åŒçš„æœ´ç´ è´å¶æ–¯
print("\n=== æœ´ç´ è´å¶æ–¯å˜ä½“æ¯”è¾ƒ ===")

# åˆ›å»ºäºŒå€¼åŒ–ç‰¹å¾
X_binary = (X > 0).astype(int)

X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(
    X_binary, y, test_size=0.2, random_state=42
)

nb_models = {
    'Gaussian': GaussianNB(),
    'Bernoulli': BernoulliNB()
}

nb_results = {}
for name, model in nb_models.items():
    if name == 'Gaussian':
        model.fit(X_train, y_train)
        score = model.score(X_test, y_test)
    else:
        model.fit(X_train_b, y_train_b)
        score = model.score(X_test_b, y_test_b)
    
    nb_results[name] = score
    print(f"{name} NB å‡†ç¡®ç‡: {score:.4f}")

# å¯è§†åŒ–æœ´ç´ è´å¶æ–¯å†³ç­–è¾¹ç•Œï¼ˆ2Dç¤ºä¾‹ï¼‰
from sklearn.decomposition import PCA

# é™ç»´åˆ°2D
pca = PCA(n_components=2)
X_2d = pca.fit_transform(X_scaled)

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

for idx, (name, model) in enumerate(nb_models.items()):
    if name == 'Gaussian':
        model.fit(X_2d, y)
        X_plot = X_2d
    else:
        X_2d_binary = (X_2d > 0).astype(int)
        model.fit(X_2d_binary, y)
        X_plot = X_2d_binary
    
    # åˆ›å»ºç½‘æ ¼
    h = 0.02
    x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1
    y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    
    if name == 'Bernoulli':
        Z = model.predict((np.c_[xx.ravel(), yy.ravel()] > 0).astype(int))
    else:
        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    axes[idx].contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)
    axes[idx].scatter(X_plot[:, 0], X_plot[:, 1], 
                      c=y, cmap=plt.cm.RdYlBu, edgecolor='black')
    axes[idx].set_title(f'{name} Naive Bayes')
    axes[idx].set_xlabel('PC1')
    axes[idx].set_ylabel('PC2')

plt.tight_layout()
plt.show()
```

## 4. å®æˆ˜é¡¹ç›®ï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹

```python
# åˆ›å»ºæ¨¡æ‹Ÿçš„ä¿¡ç”¨å¡äº¤æ˜“æ•°æ®
def create_credit_card_data(n_samples=10000):
    """åˆ›å»ºä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹æ•°æ®é›†"""
    np.random.seed(42)
    
    # æ­£å¸¸äº¤æ˜“ (95%)
    n_normal = int(n_samples * 0.95)
    normal_amount = np.random.lognormal(3, 1.5, n_normal)
    normal_hour = np.random.normal(14, 6, n_normal) % 24
    normal_merchant = np.random.choice(100, n_normal)
    normal_country = np.random.choice(50, n_normal, p=np.concatenate([
        np.array([0.8]), np.ones(49) * 0.2/49
    ]))
    
    # æ¬ºè¯ˆäº¤æ˜“ (5%)
    n_fraud = n_samples - n_normal
    fraud_amount = np.concatenate([
        np.random.lognormal(5, 1, n_fraud//2),  # å¤§é¢æ¬ºè¯ˆ
        np.random.uniform(1, 50, n_fraud//2)    # å°é¢æµ‹è¯•
    ])
    fraud_hour = np.random.uniform(0, 24, n_fraud)  # ä»»æ„æ—¶é—´
    fraud_merchant = np.random.choice(100, n_fraud)
    fraud_country = np.random.choice(50, n_fraud)  # éšæœºå›½å®¶
    
    # åˆå¹¶æ•°æ®
    features = np.vstack([
        np.column_stack([normal_amount, normal_hour, 
                        normal_merchant, normal_country]),
        np.column_stack([fraud_amount, fraud_hour, 
                        fraud_merchant, fraud_country])
    ])
    
    labels = np.concatenate([np.zeros(n_normal), np.ones(n_fraud)])
    
    # æ‰“ä¹±æ•°æ®
    shuffle_idx = np.random.permutation(n_samples)
    
    return features[shuffle_idx], labels[shuffle_idx].astype(int)

# åˆ›å»ºæ•°æ®
X_credit, y_credit = create_credit_card_data()

# æ·»åŠ æ›´å¤šç‰¹å¾
X_credit_enhanced = np.column_stack([
    X_credit,
    X_credit[:, 0] ** 2,  # é‡‘é¢å¹³æ–¹
    np.sin(X_credit[:, 1] * np.pi / 12),  # æ—¶é—´å‘¨æœŸæ€§
    X_credit[:, 0] * X_credit[:, 1],  # äº¤äº’ç‰¹å¾
])

print("ä¿¡ç”¨å¡æ•°æ®é›†:")
print(f"æ ·æœ¬æ•°: {len(X_credit_enhanced)}")
print(f"ç‰¹å¾æ•°: {X_credit_enhanced.shape[1]}")
print(f"æ¬ºè¯ˆæ¯”ä¾‹: {y_credit.mean():.2%}")

# åˆ’åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(
    X_credit_enhanced, y_credit, test_size=0.2, 
    stratify=y_credit, random_state=42
)

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# è®­ç»ƒå¤šä¸ªæ¨¡å‹
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_recall_curve

models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'Naive Bayes': GaussianNB(),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)
}

results = []
plt.figure(figsize=(15, 10))

for idx, (name, model) in enumerate(models.items(), 1):
    # è®­ç»ƒ
    model.fit(X_train_scaled, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    # è¯„ä¼°
    metrics = evaluate_model(y_test, y_pred, y_pred_proba)
    metrics['æ¨¡å‹'] = name
    results.append(metrics)
    
    # PRæ›²çº¿ï¼ˆå¯¹ä¸å¹³è¡¡æ•°æ®æ›´æœ‰æ„ä¹‰ï¼‰
    plt.subplot(2, 3, idx)
    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
    plt.plot(recall, precision, lw=2)
    plt.xlabel('å¬å›ç‡')
    plt.ylabel('ç²¾ç¡®ç‡')
    plt.title(f'{name}\nAUC: {metrics["AUC"]:.3f}')
    plt.grid(True, alpha=0.3)

# æ¯”è¾ƒè¡¨
plt.subplot(2, 3, 5)
results_df = pd.DataFrame(results)
results_df = results_df.set_index('æ¨¡å‹')

# ç»˜åˆ¶æŒ‡æ ‡å¯¹æ¯”
metrics_to_plot = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°']
results_df[metrics_to_plot].plot(kind='bar', ax=plt.gca())
plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”')
plt.xlabel('æ¨¡å‹')
plt.ylabel('åˆ†æ•°')
plt.legend(loc='lower right')
plt.xticks(rotation=45)

# ç‰¹å¾é‡è¦æ€§ï¼ˆRandom Forestï¼‰
plt.subplot(2, 3, 6)
rf_model = models['Random Forest']
feature_names = ['é‡‘é¢', 'æ—¶é—´', 'å•†æˆ·', 'å›½å®¶', 'é‡‘é¢Â²', 
                 'æ—¶é—´å‘¨æœŸ', 'é‡‘é¢Ã—æ—¶é—´']
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1][:5]

plt.bar(range(5), importances[indices])
plt.xticks(range(5), [feature_names[i] for i in indices], rotation=45)
plt.title('Top 5 é‡è¦ç‰¹å¾')
plt.xlabel('ç‰¹å¾')
plt.ylabel('é‡è¦æ€§')

plt.tight_layout()
plt.show()

print("\næ¨¡å‹æ€§èƒ½æ€»ç»“:")
print(results_df.round(4))

# æˆæœ¬æ•æ„Ÿå­¦ä¹ 
print("\n=== æˆæœ¬æ•æ„Ÿå­¦ä¹  ===")

# å‡è®¾æ¼æ£€æ¬ºè¯ˆçš„æˆæœ¬æ˜¯è¯¯æŠ¥çš„10å€
class_weight = {0: 1, 1: 10}

weighted_models = {
    'Weighted LR': LogisticRegression(class_weight=class_weight, random_state=42),
    'Weighted SVM': SVC(class_weight=class_weight, probability=True, random_state=42),
    'Weighted RF': RandomForestClassifier(class_weight=class_weight, 
                                          n_estimators=100, random_state=42)
}

for name, model in weighted_models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    
    print(f"\n{name}:")
    print(f"  ç²¾ç¡®ç‡: {precision_score(y_test, y_pred):.4f}")
    print(f"  å¬å›ç‡: {recall_score(y_test, y_pred):.4f}")
    
    # è®¡ç®—æ€»æˆæœ¬
    cm = confusion_matrix(y_test, y_pred)
    fn_cost = cm[1, 0] * 1000  # æ¼æ£€æ¬ºè¯ˆæˆæœ¬
    fp_cost = cm[0, 1] * 100   # è¯¯æŠ¥æˆæœ¬
    total_cost = fn_cost + fp_cost
    print(f"  æ€»æˆæœ¬: ${total_cost:,.0f}")
```

## 5. é«˜çº§æŠ€å·§ï¼šé›†æˆåˆ†ç±»å™¨

```python
from sklearn.ensemble import VotingClassifier
from sklearn.calibration import CalibratedClassifierCV

# åˆ›å»ºé›†æˆåˆ†ç±»å™¨
ensemble = VotingClassifier(
    estimators=[
        ('lr', LogisticRegression(random_state=42)),
        ('svm', SVC(probability=True, random_state=42)),
        ('nb', GaussianNB())
    ],
    voting='soft'  # ä½¿ç”¨æ¦‚ç‡æŠ•ç¥¨
)

# è®­ç»ƒé›†æˆæ¨¡å‹
ensemble.fit(X_train_scaled, y_train)
y_pred_ensemble = ensemble.predict(X_test_scaled)

print("é›†æˆåˆ†ç±»å™¨æ€§èƒ½:")
print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred_ensemble):.4f}")
print(f"F1åˆ†æ•°: {f1_score(y_test, y_pred_ensemble):.4f}")

# æ¦‚ç‡æ ¡å‡†
print("\n=== æ¦‚ç‡æ ¡å‡† ===")

# æ ¡å‡†SVMçš„æ¦‚ç‡è¾“å‡º
svm_calibrated = CalibratedClassifierCV(
    SVC(random_state=42), 
    method='sigmoid'
)
svm_calibrated.fit(X_train_scaled, y_train)

# æ¯”è¾ƒæ ¡å‡†å‰å
svm_uncalibrated = SVC(probability=True, random_state=42)
svm_uncalibrated.fit(X_train_scaled, y_train)

# è·å–æ¦‚ç‡
prob_uncalibrated = svm_uncalibrated.predict_proba(X_test_scaled)[:, 1]
prob_calibrated = svm_calibrated.predict_proba(X_test_scaled)[:, 1]

# å¯è§†åŒ–æ ¡å‡†æ•ˆæœ
from sklearn.calibration import calibration_curve

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# æ ¡å‡†æ›²çº¿
for probs, name in [(prob_uncalibrated, 'æœªæ ¡å‡†'), 
                     (prob_calibrated, 'å·²æ ¡å‡†')]:
    fraction_pos, mean_pred = calibration_curve(y_test, probs, n_bins=10)
    axes[0].plot(mean_pred, fraction_pos, 'o-', label=name)

axes[0].plot([0, 1], [0, 1], 'k--', label='å®Œç¾æ ¡å‡†')
axes[0].set_xlabel('å¹³å‡é¢„æµ‹æ¦‚ç‡')
axes[0].set_ylabel('æ­£ä¾‹æ¯”ä¾‹')
axes[0].set_title('æ¦‚ç‡æ ¡å‡†æ›²çº¿')
axes[0].legend()

# æ¦‚ç‡åˆ†å¸ƒ
axes[1].hist(prob_uncalibrated, bins=20, alpha=0.5, 
             label='æœªæ ¡å‡†', density=True)
axes[1].hist(prob_calibrated, bins=20, alpha=0.5, 
             label='å·²æ ¡å‡†', density=True)
axes[1].set_xlabel('é¢„æµ‹æ¦‚ç‡')
axes[1].set_ylabel('å¯†åº¦')
axes[1].set_title('æ¦‚ç‡åˆ†å¸ƒ')
axes[1].legend()

plt.tight_layout()
plt.show()
```

## æœ€ä½³å®è·µå»ºè®®

### 1. ç®—æ³•é€‰æ‹©æŒ‡å—
- **é€»è¾‘å›å½’**ï¼šçº¿æ€§å¯åˆ†ã€éœ€è¦æ¦‚ç‡è¾“å‡ºã€å¯è§£é‡Šæ€§è¦æ±‚é«˜
- **SVM**ï¼šéçº¿æ€§é—®é¢˜ã€é«˜ç»´æ•°æ®ã€æ ·æœ¬é‡ä¸­ç­‰
- **æœ´ç´ è´å¶æ–¯**ï¼šæ–‡æœ¬åˆ†ç±»ã€ç‰¹å¾ç‹¬ç«‹ã€è®­ç»ƒæ•°æ®å°‘

### 2. å¤„ç†ä¸å¹³è¡¡æ•°æ®
```python
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

# SMOTEè¿‡é‡‡æ ·
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)

print(f"åŸå§‹è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ: {np.bincount(y_train)}")
print(f"SMOTEåç±»åˆ«åˆ†å¸ƒ: {np.bincount(y_resampled)}")
```

### 3. ç‰¹å¾å·¥ç¨‹
- ç‰¹å¾ç¼©æ”¾ï¼ˆæ ‡å‡†åŒ–/å½’ä¸€åŒ–ï¼‰
- ç‰¹å¾é€‰æ‹©ï¼ˆäº’ä¿¡æ¯ã€å¡æ–¹æ£€éªŒï¼‰
- ç‰¹å¾åˆ›é€ ï¼ˆå¤šé¡¹å¼ç‰¹å¾ã€äº¤äº’ç‰¹å¾ï¼‰

### 4. è¯„ä¼°æŒ‡æ ‡é€‰æ‹©
- å¹³è¡¡æ•°æ®ï¼šå‡†ç¡®ç‡
- ä¸å¹³è¡¡æ•°æ®ï¼šF1åˆ†æ•°ã€AUC-ROC
- æˆæœ¬æ•æ„Ÿï¼šè‡ªå®šä¹‰æˆæœ¬å‡½æ•°

## ä¸‹ä¸€æ­¥å­¦ä¹ 
- [é›†æˆå­¦ä¹ ](ensemble.md) - ç»„åˆå¤šä¸ªæ¨¡å‹è·å¾—æ›´å¥½æ€§èƒ½
- [è¶…å‚æ•°è°ƒä¼˜](hyperparameter_tuning.md) - ä¼˜åŒ–æ¨¡å‹å‚æ•°
- [ç‰¹å¾å·¥ç¨‹](feature_engineering.md) - æå‡æ¨¡å‹è¾“å…¥è´¨é‡