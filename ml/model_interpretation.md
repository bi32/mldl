# æ¨¡å‹è§£é‡Šä¸å¯è§£é‡Šæ€§ ğŸ”

ç†è§£æœºå™¨å­¦ä¹ æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ï¼Œè®©AIä¸å†æ˜¯é»‘ç›’ã€‚

## 1. æ¨¡å‹å¯è§£é‡Šæ€§æ¦‚è¿° ğŸŒŸ

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings('ignore')

class ModelInterpretability:
    """æ¨¡å‹å¯è§£é‡Šæ€§åŸºç¡€"""
    
    def __init__(self):
        self.interpretation_methods = {
            "å†…åœ¨å¯è§£é‡Š": ["çº¿æ€§æ¨¡å‹", "å†³ç­–æ ‘", "è§„åˆ™å­¦ä¹ "],
            "äº‹åè§£é‡Š": ["LIME", "SHAP", "Anchor", "CounterfactualExplanations"],
            "å…¨å±€è§£é‡Š": ["ç‰¹å¾é‡è¦æ€§", "éƒ¨åˆ†ä¾èµ–å›¾", "ALEå›¾"],
            "å±€éƒ¨è§£é‡Š": ["LIME", "SHAPå€¼", "åäº‹å®è§£é‡Š"]
        }
    
    def explain_linear_model(self, model, feature_names):
        """è§£é‡Šçº¿æ€§æ¨¡å‹"""
        if hasattr(model, 'coef_'):
            coefficients = model.coef_
            if len(coefficients.shape) > 1:
                coefficients = coefficients[0]
            
            # åˆ›å»ºç³»æ•°DataFrame
            coef_df = pd.DataFrame({
                'Feature': feature_names,
                'Coefficient': coefficients,
                'Abs_Coefficient': np.abs(coefficients)
            })
            coef_df = coef_df.sort_values('Abs_Coefficient', ascending=False)
            
            # å¯è§†åŒ–
            plt.figure(figsize=(10, 6))
            plt.barh(coef_df['Feature'][:15], coef_df['Coefficient'][:15])
            plt.xlabel('Coefficient Value')
            plt.title('Linear Model Feature Coefficients')
            plt.tight_layout()
            plt.show()
            
            return coef_df
    
    def explain_tree_model(self, model, feature_names):
        """è§£é‡Šæ ‘æ¨¡å‹"""
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
            
            # åˆ›å»ºé‡è¦æ€§DataFrame
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': importances
            })
            importance_df = importance_df.sort_values('Importance', ascending=False)
            
            # å¯è§†åŒ–
            plt.figure(figsize=(10, 6))
            plt.barh(importance_df['Feature'][:15], importance_df['Importance'][:15])
            plt.xlabel('Feature Importance')
            plt.title('Tree Model Feature Importances')
            plt.tight_layout()
            plt.show()
            
            return importance_df
```

## 2. SHAP (SHapley Additive exPlanations) ğŸ’¡

```python
import shap

class SHAPExplainer:
    """SHAPè§£é‡Šå™¨"""
    
    def __init__(self, model, X_train):
        self.model = model
        self.X_train = X_train
        self.explainer = None
        self.shap_values = None
    
    def create_explainer(self):
        """åˆ›å»ºSHAPè§£é‡Šå™¨"""
        model_type = type(self.model).__name__
        
        if 'Tree' in model_type or 'Forest' in model_type or 'XGB' in model_type:
            # æ ‘æ¨¡å‹ä½¿ç”¨TreeExplainer
            self.explainer = shap.TreeExplainer(self.model)
        elif 'Linear' in model_type:
            # çº¿æ€§æ¨¡å‹ä½¿ç”¨LinearExplainer
            self.explainer = shap.LinearExplainer(self.model, self.X_train)
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨KernelExplainer
            self.explainer = shap.KernelExplainer(
                self.model.predict, 
                shap.sample(self.X_train, 100)
            )
        
        return self.explainer
    
    def explain_global(self, X):
        """å…¨å±€è§£é‡Š"""
        if self.explainer is None:
            self.create_explainer()
        
        # è®¡ç®—SHAPå€¼
        self.shap_values = self.explainer.shap_values(X)
        
        # å¦‚æœæ˜¯å¤šç±»åˆ†ç±»ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªç±»
        if isinstance(self.shap_values, list):
            self.shap_values = self.shap_values[0]
        
        # æ‘˜è¦å›¾
        plt.figure(figsize=(12, 8))
        shap.summary_plot(self.shap_values, X, show=False)
        plt.tight_layout()
        plt.show()
        
        # ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
        plt.figure(figsize=(10, 6))
        shap.summary_plot(self.shap_values, X, plot_type="bar", show=False)
        plt.tight_layout()
        plt.show()
        
        return self.shap_values
    
    def explain_instance(self, instance_idx, X):
        """è§£é‡Šå•ä¸ªå®ä¾‹"""
        if self.shap_values is None:
            self.explain_global(X)
        
        # ç€‘å¸ƒå›¾
        shap.waterfall_plot(
            shap.Explanation(
                values=self.shap_values[instance_idx],
                base_values=self.explainer.expected_value,
                data=X.iloc[instance_idx] if hasattr(X, 'iloc') else X[instance_idx],
                feature_names=X.columns.tolist() if hasattr(X, 'columns') else None
            )
        )
        
        # åŠ›å›¾
        shap.force_plot(
            self.explainer.expected_value,
            self.shap_values[instance_idx],
            X.iloc[instance_idx] if hasattr(X, 'iloc') else X[instance_idx],
            matplotlib=True
        )
        plt.show()
    
    def dependence_plots(self, X, feature_names=None):
        """ä¾èµ–å›¾"""
        if self.shap_values is None:
            self.explain_global(X)
        
        if feature_names is None:
            feature_names = X.columns if hasattr(X, 'columns') else range(X.shape[1])
        
        # ä¸ºå‰4ä¸ªæœ€é‡è¦çš„ç‰¹å¾ç»˜åˆ¶ä¾èµ–å›¾
        feature_importance = np.abs(self.shap_values).mean(axis=0)
        top_features = np.argsort(feature_importance)[-4:]
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        axes = axes.flatten()
        
        for idx, feature_idx in enumerate(top_features):
            shap.dependence_plot(
                feature_idx, 
                self.shap_values, 
                X,
                ax=axes[idx],
                show=False
            )
        
        plt.tight_layout()
        plt.show()
    
    def interaction_effects(self, X):
        """äº¤äº’æ•ˆåº”åˆ†æ"""
        if self.explainer is None:
            self.create_explainer()
        
        # è®¡ç®—äº¤äº’SHAPå€¼
        shap_interaction_values = self.explainer.shap_interaction_values(X)
        
        # å¦‚æœæ˜¯å¤šç±»åˆ†ç±»ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªç±»
        if isinstance(shap_interaction_values, list):
            shap_interaction_values = shap_interaction_values[0]
        
        # ç»˜åˆ¶äº¤äº’æ•ˆåº”çƒ­å›¾
        mean_interaction = np.abs(shap_interaction_values).mean(axis=0)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(mean_interaction, annot=True, fmt='.3f', cmap='coolwarm')
        plt.title('SHAP Interaction Values')
        plt.show()
        
        return shap_interaction_values
```

## 3. LIME (Local Interpretable Model-agnostic Explanations) ğŸ¯

```python
from lime.lime_tabular import LimeTabularExplainer
from lime.lime_text import LimeTextExplainer
from lime.lime_image import LimeImageExplainer

class LIMEExplainer:
    """LIMEè§£é‡Šå™¨"""
    
    def __init__(self, training_data, feature_names, class_names=None, mode='classification'):
        self.training_data = training_data
        self.feature_names = feature_names
        self.class_names = class_names
        self.mode = mode
        self.explainer = None
    
    def create_tabular_explainer(self):
        """åˆ›å»ºè¡¨æ ¼æ•°æ®è§£é‡Šå™¨"""
        self.explainer = LimeTabularExplainer(
            self.training_data,
            feature_names=self.feature_names,
            class_names=self.class_names,
            mode=self.mode,
            discretize_continuous=True
        )
        return self.explainer
    
    def explain_instance_tabular(self, model, instance, num_features=10):
        """è§£é‡Šè¡¨æ ¼æ•°æ®å®ä¾‹"""
        if self.explainer is None:
            self.create_tabular_explainer()
        
        # ç”Ÿæˆè§£é‡Š
        if self.mode == 'classification':
            exp = self.explainer.explain_instance(
                instance,
                model.predict_proba,
                num_features=num_features
            )
        else:
            exp = self.explainer.explain_instance(
                instance,
                model.predict,
                num_features=num_features
            )
        
        # æ˜¾ç¤ºè§£é‡Š
        exp.show_in_notebook(show_table=True)
        
        # è·å–è§£é‡Šä½œä¸ºåˆ—è¡¨
        explanation_list = exp.as_list()
        
        # å¯è§†åŒ–
        fig = exp.as_pyplot_figure()
        plt.tight_layout()
        plt.show()
        
        return exp
    
    def explain_text(self, model, text, num_features=10):
        """è§£é‡Šæ–‡æœ¬åˆ†ç±»"""
        text_explainer = LimeTextExplainer(class_names=self.class_names)
        
        exp = text_explainer.explain_instance(
            text,
            model.predict_proba,
            num_features=num_features
        )
        
        # æ˜¾ç¤ºè§£é‡Š
        exp.show_in_notebook(text=True)
        
        return exp
    
    def explain_image(self, model, image, num_samples=1000):
        """è§£é‡Šå›¾åƒåˆ†ç±»"""
        image_explainer = LimeImageExplainer()
        
        exp = image_explainer.explain_instance(
            image,
            model.predict_proba,
            top_labels=5,
            hide_color=0,
            num_samples=num_samples
        )
        
        # æ˜¾ç¤ºè§£é‡Š
        from skimage.segmentation import mark_boundaries
        
        temp, mask = exp.get_image_and_mask(
            exp.top_labels[0],
            positive_only=True,
            num_features=5,
            hide_rest=False
        )
        
        plt.figure(figsize=(10, 10))
        plt.imshow(mark_boundaries(temp / 255.0, mask))
        plt.axis('off')
        plt.show()
        
        return exp
```

## 4. ç‰¹å¾é‡è¦æ€§åˆ†æ ğŸ“Š

```python
class FeatureImportanceAnalysis:
    """ç‰¹å¾é‡è¦æ€§åˆ†æ"""
    
    def __init__(self):
        self.importance_scores = {}
    
    def permutation_importance(self, model, X, y, n_repeats=10):
        """æ’åˆ—é‡è¦æ€§"""
        from sklearn.inspection import permutation_importance
        
        result = permutation_importance(
            model, X, y,
            n_repeats=n_repeats,
            random_state=42
        )
        
        # åˆ›å»ºDataFrame
        importance_df = pd.DataFrame({
            'Feature': X.columns if hasattr(X, 'columns') else range(X.shape[1]),
            'Importance': result.importances_mean,
            'Std': result.importances_std
        })
        importance_df = importance_df.sort_values('Importance', ascending=False)
        
        # å¯è§†åŒ–
        plt.figure(figsize=(10, 6))
        plt.errorbar(
            importance_df['Feature'][:15],
            importance_df['Importance'][:15],
            yerr=importance_df['Std'][:15],
            fmt='o',
            capsize=5
        )
        plt.xlabel('Feature')
        plt.ylabel('Permutation Importance')
        plt.title('Feature Permutation Importance')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()
        
        self.importance_scores['permutation'] = importance_df
        return importance_df
    
    def drop_column_importance(self, model, X, y, cv=5):
        """åˆ é™¤åˆ—é‡è¦æ€§"""
        from sklearn.model_selection import cross_val_score
        from sklearn.base import clone
        
        # åŸºå‡†åˆ†æ•°
        base_score = cross_val_score(
            clone(model), X, y, cv=cv, scoring='accuracy'
        ).mean()
        
        importances = []
        
        for col in X.columns if hasattr(X, 'columns') else range(X.shape[1]):
            # åˆ é™¤è¯¥åˆ—
            X_dropped = X.drop(columns=[col]) if hasattr(X, 'drop') else np.delete(X, col, axis=1)
            
            # è®¡ç®—åˆ†æ•°
            score = cross_val_score(
                clone(model), X_dropped, y, cv=cv, scoring='accuracy'
            ).mean()
            
            # é‡è¦æ€§ = åŸºå‡†åˆ†æ•° - åˆ é™¤ååˆ†æ•°
            importance = base_score - score
            importances.append(importance)
        
        # åˆ›å»ºDataFrame
        importance_df = pd.DataFrame({
            'Feature': X.columns if hasattr(X, 'columns') else range(X.shape[1]),
            'Importance': importances
        })
        importance_df = importance_df.sort_values('Importance', ascending=False)
        
        self.importance_scores['drop_column'] = importance_df
        return importance_df
    
    def compare_importance_methods(self):
        """æ¯”è¾ƒä¸åŒé‡è¦æ€§æ–¹æ³•"""
        if len(self.importance_scores) < 2:
            print("éœ€è¦è‡³å°‘ä¸¤ç§é‡è¦æ€§è®¡ç®—æ–¹æ³•")
            return
        
        # åˆå¹¶æ‰€æœ‰é‡è¦æ€§åˆ†æ•°
        merged_df = None
        for method, df in self.importance_scores.items():
            if merged_df is None:
                merged_df = df[['Feature', 'Importance']].rename(
                    columns={'Importance': method}
                )
            else:
                merged_df = merged_df.merge(
                    df[['Feature', 'Importance']].rename(
                        columns={'Importance': method}
                    ),
                    on='Feature'
                )
        
        # å½’ä¸€åŒ–
        for col in merged_df.columns[1:]:
            merged_df[col] = (merged_df[col] - merged_df[col].min()) / \
                            (merged_df[col].max() - merged_df[col].min())
        
        # å¯è§†åŒ–
        merged_df.set_index('Feature').plot(kind='bar', figsize=(12, 6))
        plt.title('Feature Importance Comparison')
        plt.ylabel('Normalized Importance')
        plt.legend(title='Method')
        plt.tight_layout()
        plt.show()
        
        return merged_df
```

## 5. éƒ¨åˆ†ä¾èµ–å›¾ (PDP) å’Œ ALE å›¾ ğŸ“ˆ

```python
from sklearn.inspection import PartialDependenceDisplay, partial_dependence

class PartialDependenceAnalysis:
    """éƒ¨åˆ†ä¾èµ–åˆ†æ"""
    
    def __init__(self, model, X, feature_names):
        self.model = model
        self.X = X
        self.feature_names = feature_names
    
    def plot_partial_dependence(self, features, kind='both'):
        """ç»˜åˆ¶éƒ¨åˆ†ä¾èµ–å›¾"""
        # åˆ›å»ºéƒ¨åˆ†ä¾èµ–æ˜¾ç¤º
        display = PartialDependenceDisplay.from_estimator(
            self.model,
            self.X,
            features,
            kind=kind,  # 'average', 'individual', or 'both'
            subsample=50,
            n_jobs=-1,
            grid_resolution=20
        )
        
        display.figure_.suptitle('Partial Dependence Plots')
        display.figure_.set_size_inches(14, 8)
        plt.tight_layout()
        plt.show()
        
        return display
    
    def plot_2d_partial_dependence(self, feature_pairs):
        """ç»˜åˆ¶2Déƒ¨åˆ†ä¾èµ–å›¾"""
        fig, axes = plt.subplots(1, len(feature_pairs), figsize=(6*len(feature_pairs), 5))
        
        if len(feature_pairs) == 1:
            axes = [axes]
        
        for idx, (feat1, feat2) in enumerate(feature_pairs):
            # è®¡ç®—2Déƒ¨åˆ†ä¾èµ–
            pd_result = partial_dependence(
                self.model,
                X=self.X,
                features=[(feat1, feat2)],
                grid_resolution=20
            )
            
            # ç»˜åˆ¶ç­‰é«˜çº¿å›¾
            XX, YY = np.meshgrid(pd_result['values'][0], pd_result['values'][1])
            Z = pd_result['average'][0].T
            
            contour = axes[idx].contourf(XX, YY, Z, levels=20, cmap='RdBu_r')
            axes[idx].set_xlabel(self.feature_names[feat1])
            axes[idx].set_ylabel(self.feature_names[feat2])
            axes[idx].set_title(f'2D PDP: {self.feature_names[feat1]} vs {self.feature_names[feat2]}')
            plt.colorbar(contour, ax=axes[idx])
        
        plt.tight_layout()
        plt.show()
    
    def accumulated_local_effects(self, feature_idx, n_bins=10):
        """ç´¯ç§¯å±€éƒ¨æ•ˆåº”ï¼ˆALEï¼‰å›¾"""
        feature_values = self.X[:, feature_idx] if isinstance(self.X, np.ndarray) else self.X.iloc[:, feature_idx]
        
        # åˆ›å»ºåˆ†ç®±
        bins = np.quantile(feature_values, np.linspace(0, 1, n_bins + 1))
        bin_indices = np.digitize(feature_values, bins) - 1
        
        ale_values = []
        bin_centers = []
        
        for i in range(n_bins):
            mask = bin_indices == i
            if mask.sum() == 0:
                continue
            
            # è·å–è¯¥ç®±ä¸­çš„æ ·æœ¬
            X_bin = self.X[mask]
            
            # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œçš„é¢„æµ‹å·®å¼‚
            X_lower = X_bin.copy()
            X_upper = X_bin.copy()
            
            if isinstance(X_lower, pd.DataFrame):
                X_lower.iloc[:, feature_idx] = bins[i]
                X_upper.iloc[:, feature_idx] = bins[i + 1]
            else:
                X_lower[:, feature_idx] = bins[i]
                X_upper[:, feature_idx] = bins[i + 1]
            
            # è®¡ç®—å·®å¼‚
            diff = self.model.predict(X_upper) - self.model.predict(X_lower)
            ale_values.append(diff.mean())
            bin_centers.append((bins[i] + bins[i + 1]) / 2)
        
        # ç´¯ç§¯å’Œä¸­å¿ƒåŒ–
        ale_cumsum = np.cumsum(ale_values)
        ale_centered = ale_cumsum - ale_cumsum.mean()
        
        # ç»˜åˆ¶ALEå›¾
        plt.figure(figsize=(8, 5))
        plt.plot(bin_centers, ale_centered, 'o-', linewidth=2, markersize=8)
        plt.xlabel(self.feature_names[feature_idx] if self.feature_names else f'Feature {feature_idx}')
        plt.ylabel('ALE')
        plt.title(f'Accumulated Local Effects: {self.feature_names[feature_idx] if self.feature_names else f"Feature {feature_idx}"}')
        plt.grid(True, alpha=0.3)
        plt.show()
        
        return bin_centers, ale_centered
```

## 6. åäº‹å®è§£é‡Š ğŸ”„

```python
class CounterfactualExplanations:
    """åäº‹å®è§£é‡Š"""
    
    def __init__(self, model, X_train, y_train):
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
    
    def find_counterfactual(self, instance, target_class, max_changes=3):
        """å¯»æ‰¾åäº‹å®å®ä¾‹"""
        original_class = self.model.predict([instance])[0]
        
        if original_class == target_class:
            print("å®ä¾‹å·²ç»å±äºç›®æ ‡ç±»åˆ«")
            return instance
        
        # æ‰¾åˆ°ç›®æ ‡ç±»åˆ«çš„æœ€è¿‘é‚»
        target_instances = self.X_train[self.y_train == target_class]
        
        # è®¡ç®—è·ç¦»
        distances = np.sum((target_instances - instance) ** 2, axis=1)
        nearest_idx = np.argmin(distances)
        nearest_target = target_instances[nearest_idx]
        
        # æ‰¾åˆ°æœ€å°æ”¹å˜
        differences = nearest_target - instance
        important_features = np.argsort(np.abs(differences))[::-1]
        
        counterfactual = instance.copy()
        changes_made = []
        
        for i, feat_idx in enumerate(important_features):
            if i >= max_changes:
                break
            
            # æ”¹å˜ç‰¹å¾å€¼
            old_value = counterfactual[feat_idx]
            counterfactual[feat_idx] = nearest_target[feat_idx]
            new_value = counterfactual[feat_idx]
            
            changes_made.append({
                'feature': feat_idx,
                'old_value': old_value,
                'new_value': new_value,
                'change': new_value - old_value
            })
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡ç±»åˆ«
            if self.model.predict([counterfactual])[0] == target_class:
                break
        
        return counterfactual, changes_made
    
    def diverse_counterfactuals(self, instance, target_class, n_counterfactuals=3):
        """ç”Ÿæˆå¤šæ ·åŒ–çš„åäº‹å®è§£é‡Š"""
        counterfactuals = []
        
        for _ in range(n_counterfactuals):
            # æ·»åŠ éšæœºæ€§ä»¥è·å¾—ä¸åŒçš„åäº‹å®
            noise = np.random.normal(0, 0.1, instance.shape)
            noisy_instance = instance + noise
            
            cf, changes = self.find_counterfactual(noisy_instance, target_class)
            counterfactuals.append({
                'counterfactual': cf,
                'changes': changes
            })
        
        return counterfactuals
    
    def actionable_recourse(self, instance, constraints):
        """å¯æ“ä½œçš„è¡¥æ•‘æªæ–½"""
        # constraints: {'feature_name': {'min': val, 'max': val, 'mutable': bool}}
        
        original_prediction = self.model.predict([instance])[0]
        desired_class = 1 - original_prediction  # å‡è®¾äºŒåˆ†ç±»
        
        # åˆ›å»ºä¼˜åŒ–é—®é¢˜
        from scipy.optimize import minimize
        
        def objective(x):
            # æœ€å°åŒ–æ”¹å˜
            return np.sum((x - instance) ** 2)
        
        def constraint(x):
            # ç¡®ä¿é¢„æµ‹ä¸ºæœŸæœ›ç±»åˆ«
            pred_proba = self.model.predict_proba([x])[0]
            return pred_proba[desired_class] - 0.5
        
        # åº”ç”¨çº¦æŸ
        bounds = []
        for i, (feat, const) in enumerate(constraints.items()):
            if const['mutable']:
                bounds.append((const['min'], const['max']))
            else:
                bounds.append((instance[i], instance[i]))
        
        # ä¼˜åŒ–
        result = minimize(
            objective,
            instance,
            method='SLSQP',
            bounds=bounds,
            constraints={'type': 'ineq', 'fun': constraint}
        )
        
        if result.success:
            return result.x, self.model.predict([result.x])[0]
        else:
            return None, None
```

## 7. æ¨¡å‹è¯Šæ–­å·¥å…· ğŸ”§

```python
class ModelDiagnostics:
    """æ¨¡å‹è¯Šæ–­å·¥å…·"""
    
    def __init__(self, model, X, y):
        self.model = model
        self.X = X
        self.y = y
    
    def confusion_matrix_analysis(self, y_true, y_pred):
        """æ··æ·†çŸ©é˜µåˆ†æ"""
        from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
        
        cm = confusion_matrix(y_true, y_pred)
        
        # å¯è§†åŒ–
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title('Confusion Matrix')
        plt.show()
        
        # è¯¦ç»†åˆ†æ
        n_classes = cm.shape[0]
        for i in range(n_classes):
            for j in range(n_classes):
                if i != j and cm[i, j] > 0:
                    print(f"ç±»åˆ« {i} è¢«è¯¯åˆ†ç±»ä¸ºç±»åˆ« {j}: {cm[i, j]} æ¬¡")
        
        return cm
    
    def error_analysis(self, X, y_true, y_pred):
        """é”™è¯¯åˆ†æ"""
        # æ‰¾å‡ºé”™è¯¯é¢„æµ‹çš„æ ·æœ¬
        errors = y_true != y_pred
        error_indices = np.where(errors)[0]
        
        if len(error_indices) == 0:
            print("æ²¡æœ‰é”™è¯¯é¢„æµ‹")
            return
        
        # åˆ†æé”™è¯¯æ ·æœ¬çš„ç‰¹å¾
        error_samples = X[error_indices]
        correct_samples = X[~errors]
        
        # ç‰¹å¾åˆ†å¸ƒæ¯”è¾ƒ
        if hasattr(X, 'columns'):
            feature_names = X.columns
        else:
            feature_names = [f'Feature_{i}' for i in range(X.shape[1])]
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()
        
        for idx, feature in enumerate(feature_names[:6]):
            if hasattr(X, 'iloc'):
                error_feat = error_samples[feature]
                correct_feat = correct_samples[feature]
            else:
                error_feat = error_samples[:, idx]
                correct_feat = correct_samples[:, idx]
            
            axes[idx].hist([correct_feat, error_feat], 
                          label=['Correct', 'Error'],
                          alpha=0.7, bins=20)
            axes[idx].set_title(f'{feature} Distribution')
            axes[idx].legend()
        
        plt.tight_layout()
        plt.show()
        
        return error_indices
    
    def calibration_analysis(self, y_true, y_proba):
        """æ ¡å‡†åˆ†æ"""
        from sklearn.calibration import calibration_curve
        
        # è®¡ç®—æ ¡å‡†æ›²çº¿
        fraction_of_positives, mean_predicted_value = calibration_curve(
            y_true, y_proba, n_bins=10
        )
        
        # ç»˜åˆ¶æ ¡å‡†å›¾
        plt.figure(figsize=(8, 6))
        plt.plot(mean_predicted_value, fraction_of_positives, 
                's-', label='Model')
        plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')
        plt.xlabel('Mean Predicted Probability')
        plt.ylabel('Fraction of Positives')
        plt.title('Calibration Plot')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()
        
        # è®¡ç®—ECE (Expected Calibration Error)
        ece = np.abs(fraction_of_positives - mean_predicted_value).mean()
        print(f'Expected Calibration Error: {ece:.4f}')
        
        return ece
```

## 8. å®æˆ˜ç¤ºä¾‹ ğŸ’¼

```python
def interpretation_pipeline_example():
    """å®Œæ•´çš„æ¨¡å‹è§£é‡Šæµç¨‹ç¤ºä¾‹"""
    from sklearn.datasets import load_breast_cancer
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    
    # åŠ è½½æ•°æ®
    data = load_breast_cancer()
    X = pd.DataFrame(data.data, columns=data.feature_names)
    y = data.target
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒæ¨¡å‹
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    print("=" * 50)
    print("æ¨¡å‹è§£é‡Šæµç¨‹ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. ç‰¹å¾é‡è¦æ€§
    print("\n1. ç‰¹å¾é‡è¦æ€§åˆ†æ")
    interpreter = ModelInterpretability()
    importance_df = interpreter.explain_tree_model(model, X.columns)
    print(importance_df.head(10))
    
    # 2. SHAPè§£é‡Š
    print("\n2. SHAPè§£é‡Š")
    shap_explainer = SHAPExplainer(model, X_train)
    shap_values = shap_explainer.explain_global(X_test)
    
    # 3. LIMEè§£é‡Š
    print("\n3. LIMEè§£é‡Šï¼ˆå•ä¸ªå®ä¾‹ï¼‰")
    lime_explainer = LIMEExplainer(
        X_train.values,
        X.columns.tolist(),
        class_names=['Malignant', 'Benign']
    )
    lime_exp = lime_explainer.explain_instance_tabular(
        model, X_test.iloc[0].values
    )
    
    # 4. éƒ¨åˆ†ä¾èµ–å›¾
    print("\n4. éƒ¨åˆ†ä¾èµ–å›¾")
    pdp_analyzer = PartialDependenceAnalysis(model, X_test, X.columns)
    pdp_analyzer.plot_partial_dependence([0, 1, 2, 3])
    
    # 5. æ¨¡å‹è¯Šæ–­
    print("\n5. æ¨¡å‹è¯Šæ–­")
    diagnostics = ModelDiagnostics(model, X_test, y_test)
    cm = diagnostics.confusion_matrix_analysis(y_test, y_pred)
    ece = diagnostics.calibration_analysis(y_test, y_proba)
    
    # 6. åäº‹å®è§£é‡Š
    print("\n6. åäº‹å®è§£é‡Š")
    cf_explainer = CounterfactualExplanations(model, X_train.values, y_train)
    cf_instance, changes = cf_explainer.find_counterfactual(
        X_test.iloc[0].values, 
        target_class=1-y_test.iloc[0]
    )
    print(f"éœ€è¦çš„æ”¹å˜: {changes}")
    
    print("\nè§£é‡Šæµç¨‹å®Œæˆï¼")
    
    return model, shap_values

# è¿è¡Œç¤ºä¾‹
model, shap_values = interpretation_pipeline_example()
```

## æœ€ä½³å®è·µæ€»ç»“ ğŸ“‹

```python
def interpretability_best_practices():
    """å¯è§£é‡Šæ€§æœ€ä½³å®è·µ"""
    
    practices = {
        "é€‰æ‹©æ–¹æ³•": [
            "çº¿æ€§æ¨¡å‹ä½¿ç”¨ç³»æ•°è§£é‡Š",
            "æ ‘æ¨¡å‹ä½¿ç”¨ç‰¹å¾é‡è¦æ€§å’ŒSHAP",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨LIMEå’Œæ³¨æ„åŠ›æœºåˆ¶",
            "å…¨å±€è§£é‡Šç”¨SHAPï¼Œå±€éƒ¨è§£é‡Šç”¨LIME"
        ],
        
        "SHAPä½¿ç”¨": [
            "TreeExplainerç”¨äºæ ‘æ¨¡å‹ï¼ˆå¿«é€Ÿï¼‰",
            "KernelExplainerç”¨äºé»‘ç›’æ¨¡å‹ï¼ˆæ…¢ï¼‰",
            "DeepExplainerç”¨äºæ·±åº¦å­¦ä¹ ",
            "ä½¿ç”¨summary_plotç†è§£å…¨å±€æ¨¡å¼"
        ],
        
        "ç‰¹å¾é‡è¦æ€§": [
            "ä½¿ç”¨å¤šç§æ–¹æ³•éªŒè¯",
            "è€ƒè™‘ç‰¹å¾ç›¸å…³æ€§çš„å½±å“",
            "æ’åˆ—é‡è¦æ€§æ›´å¯é ",
            "æ³¨æ„æ•°æ®æ³„éœ²"
        ],
        
        "å¯è§†åŒ–": [
            "éƒ¨åˆ†ä¾èµ–å›¾å±•ç¤ºç‰¹å¾æ•ˆåº”",
            "SHAPç€‘å¸ƒå›¾è§£é‡Šå•ä¸ªé¢„æµ‹",
            "æ··æ·†çŸ©é˜µåˆ†æé”™è¯¯æ¨¡å¼",
            "æ ¡å‡†å›¾æ£€æŸ¥æ¦‚ç‡å¯é æ€§"
        ],
        
        "æŠ¥å‘Šæ’°å†™": [
            "ä»ä¸šåŠ¡è§’åº¦è§£é‡Š",
            "æä¾›å…·ä½“æ¡ˆä¾‹",
            "ä½¿ç”¨ç®€å•çš„è¯­è¨€",
            "åŒ…å«ä¸ç¡®å®šæ€§è¯´æ˜"
        ]
    }
    
    return practices

# è§£é‡Šæ€§æ£€æŸ¥æ¸…å•
interpretation_checklist = """
æ¨¡å‹è§£é‡Šæ£€æŸ¥æ¸…å•ï¼š

â–¡ å…¨å±€è§£é‡Š
  - ç‰¹å¾é‡è¦æ€§æ’åº
  - ç‰¹å¾ä¹‹é—´çš„äº¤äº’æ•ˆåº”
  - æ¨¡å‹æ•´ä½“è¡Œä¸ºæ¨¡å¼

â–¡ å±€éƒ¨è§£é‡Š
  - å•ä¸ªé¢„æµ‹çš„è§£é‡Š
  - å…³é”®ç‰¹å¾çš„è´¡çŒ®
  - åäº‹å®æƒ…å†µ

â–¡ æ¨¡å‹è¯Šæ–­
  - æ ¡å‡†æ€§æ£€æŸ¥
  - é”™è¯¯æ¡ˆä¾‹åˆ†æ
  - åå·®æ£€æµ‹

â–¡ å¯è§†åŒ–
  - ç‰¹å¾é‡è¦æ€§å›¾
  - éƒ¨åˆ†ä¾èµ–å›¾
  - SHAPæ‘˜è¦å›¾
  - æ··æ·†çŸ©é˜µ

â–¡ æ–‡æ¡£è®°å½•
  - æ–¹æ³•è¯´æ˜
  - å±€é™æ€§è¯´æ˜
  - ä¸šåŠ¡è§£é‡Š
"""

print("æ¨¡å‹è§£é‡ŠæŒ‡å—åŠ è½½å®Œæˆï¼")
```

## ä¸‹ä¸€æ­¥å­¦ä¹ 
- [ç‰¹å¾å·¥ç¨‹](feature_engineering.md) - åˆ›å»ºå¯è§£é‡Šçš„ç‰¹å¾
- [æ¨¡å‹è¯„ä¼°](evaluation.md) - å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½
- [AutoML](automl.md) - è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ 